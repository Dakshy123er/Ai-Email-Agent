{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "kpH6vQBWB_6N",
        "outputId": "d7373d36-aa3c-45ce-dc72-750418153d48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep 15 11:01:56 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Cell 0 - GPU check\n",
        "!nvidia-smi || echo \"No GPU detected - please set Runtime -> Change runtime type -> GPU\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1 - install libs\n",
        "!pip install -q -U \"transformers>=4.34.0\" datasets accelerate peft bitsandbytes safetensors evaluate sentencepiece\n",
        "\n",
        "\n",
        "import transformers, datasets, accelerate, peft, sys\n",
        "print(\"transformers\", transformers.__version__)\n",
        "print(\"datasets\", datasets.__version__)\n",
        "print(\"accelerate\", accelerate.__version__)\n",
        "print(\"peft\", peft.__version__)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "R2H5SJUsCe9l",
        "outputId": "aaebbcbe-a436-4b7e-bd59-d9754936bd2b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25htransformers 4.56.1\n",
            "datasets 4.0.0\n",
            "accelerate 1.10.1\n",
            "peft 0.17.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2 - upload dataset files\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # select train.jsonl & valid.jsonl (or all.jsonl)\n",
        "print(\"Uploaded:\", list(uploaded.keys()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "fYH2lq0GC0cQ",
        "outputId": "f1441ca3-2cc4-4b23-b536-a0f0239ed6f5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bf485c7d-8de4-49fb-9285-df93b3182e9a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bf485c7d-8de4-49fb-9285-df93b3182e9a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving train.jsonl to train.jsonl\n",
            "Saving valid.jsonl to valid.jsonl\n",
            "Uploaded: ['train.jsonl', 'valid.jsonl']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3 - check and auto-fix swapped train/valid if sizes were swapped\n",
        "import os, itertools\n",
        "\n",
        "def count_lines(path):\n",
        "    if not os.path.exists(path): return 0\n",
        "    with open(path,'r',encoding='utf-8') as f:\n",
        "        return sum(1 for _ in f)\n",
        "\n",
        "# If user uploaded all.jsonl, split it\n",
        "if os.path.exists(\"all.jsonl\") and not (os.path.exists(\"train.jsonl\") or os.path.exists(\"valid.jsonl\")):\n",
        "    from datasets import load_dataset\n",
        "    ds = load_dataset(\"json\", data_files={\"all\":\"all.jsonl\"})[\"all\"]\n",
        "    split = ds.train_test_split(test_size=0.1, seed=42)\n",
        "    split[\"train\"].to_json(\"train.jsonl\", orient=\"records\", lines=True)\n",
        "    split[\"test\"].to_json(\"valid.jsonl\", orient=\"records\", lines=True)\n",
        "    print(\"Split all.jsonl into train.jsonl and valid.jsonl\")\n",
        "\n",
        "train_count = count_lines(\"train.jsonl\")\n",
        "valid_count = count_lines(\"valid.jsonl\")\n",
        "print(\"Before fix - train.jsonl:\", train_count, \"valid.jsonl:\", valid_count)\n",
        "\n",
        "# If both exist and train is smaller than valid, swap them (common accidental swap)\n",
        "if train_count > 0 and valid_count > 0 and train_count < valid_count:\n",
        "    print(\"Detected train smaller than valid → swapping files so train becomes the larger file.\")\n",
        "    os.rename(\"train.jsonl\", \"tmp_small.jsonl\")\n",
        "    os.rename(\"valid.jsonl\", \"train.jsonl\")\n",
        "    os.rename(\"tmp_small.jsonl\", \"valid.jsonl\")\n",
        "\n",
        "train_count = count_lines(\"train.jsonl\")\n",
        "valid_count = count_lines(\"valid.jsonl\")\n",
        "print(\"After fix - train.jsonl:\", train_count, \"valid.jsonl:\", valid_count)\n",
        "\n",
        "# show first line of each\n",
        "def show_first(path):\n",
        "    if not os.path.exists(path):\n",
        "        print(path, \"missing\")\n",
        "        return\n",
        "    with open(path,'r',encoding='utf-8') as f:\n",
        "        print(\"---\", path, \"first line ---\")\n",
        "        print(f.readline().strip())\n",
        "\n",
        "show_first(\"train.jsonl\")\n",
        "show_first(\"valid.jsonl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GctMMBOwC5sX",
        "outputId": "d981aac3-fc6e-4729-b22c-69fb8a870cf0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before fix - train.jsonl: 50 valid.jsonl: 450\n",
            "Detected train smaller than valid → swapping files so train becomes the larger file.\n",
            "After fix - train.jsonl: 450 valid.jsonl: 50\n",
            "--- train.jsonl first line ---\n",
            "{\"prompt\": \"Instruction: Draft an email to a professor asking for a 3-day extension on an assignment due to illness. Include polite tone, class name, and mention you will submit by the new date.\", \"completion\": \"Subject: Request for 3-day extension on Biomechanics assignment\\n\\nDear Dr. Kapoor,\\n\\nI hope you are well. I am writing to request a 3-day extension for the homework for Biomechanics currently due on September 19, 2025. I have been unwell and, as a result, was unable to work on the assignment this week to the standard I aim for. I respectfully request permission to submit the homework by September 22, 2025. I assure you I will submit it by that date and complete it to the best of my ability.\\n\\nThank you for your understanding and consideration.\\n\\nSincerely,\\nNeha Roll No. 540552\\nBiomechanics\"}\n",
            "--- valid.jsonl first line ---\n",
            "{\"prompt\": \"Instruction: Draft an email to a professor asking for a 3-day extension on an assignment due to illness. Include polite tone, class name, and mention you will submit by the new date.\", \"completion\": \"Subject: Request for 3-day extension on Signal Processing assignment\\n\\nDear Dr. Sharma,\\n\\nI hope you are well. I am writing to request a 3-day extension for the final deliverable for Signal Processing currently due on September 18, 2025. I have been unwell and, as a result, was unable to work on the assignment this week to the standard I aim for. I respectfully request permission to submit the final deliverable by September 21, 2025. I assure you I will submit it by that date and complete it to the best of my ability.\\n\\nThank you for your understanding and consideration.\\n\\nSincerely,\\nAarav Roll No. 407618\\nSignal Processing\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4 - write train_lora.py\n",
        "%%writefile train_lora.py\n",
        "import os\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling, TrainingArguments, Trainer\n",
        "from peft import LoraConfig, get_peft_model\n",
        "import torch\n",
        "\n",
        "# ==== Edit these if needed ====\n",
        "MODEL_NAME = \"distilgpt2\"   # small & runs on 8GB\n",
        "OUTPUT_DIR = \"lora-output\"\n",
        "TRAIN_FILE = \"train.jsonl\"\n",
        "VALID_FILE = \"valid.jsonl\"\n",
        "BATCH_SIZE = 2\n",
        "EPOCHS = 3\n",
        "MAX_LENGTH = 512\n",
        "GRADIENT_ACCUM_STEPS = 4\n",
        "LEARNING_RATE = 2e-4\n",
        "# ==============================\n",
        "\n",
        "if not (os.path.exists(TRAIN_FILE) and os.path.exists(VALID_FILE)):\n",
        "    raise FileNotFoundError(\"Please upload train.jsonl and valid.jsonl into Colab working dir.\")\n",
        "\n",
        "dataset = load_dataset(\"json\", data_files={\"train\": TRAIN_FILE, \"validation\": VALID_FILE})\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "\n",
        "def preprocess_batch(batch):\n",
        "    texts = [p + c for p, c in zip(batch[\"prompt\"], batch[\"completion\"])]\n",
        "    return tokenizer(texts, truncation=True, padding=\"max_length\", max_length=MAX_LENGTH)\n",
        "\n",
        "tokenized = dataset.map(preprocess_batch, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(device)\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    gradient_accumulation_steps=GRADIENT_ACCUM_STEPS,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    logging_steps=50,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    fp16=True,\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized[\"train\"],\n",
        "    eval_dataset=tokenized[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "print(\"Running evaluation on validation set...\")\n",
        "metrics = trainer.evaluate(eval_dataset=tokenized[\"validation\"])\n",
        "print(\"Evaluation metrics:\", metrics)\n",
        "\n",
        "model.save_pretrained(OUTPUT_DIR)\n",
        "tokenizer.save_pretrained(OUTPUT_DIR)\n",
        "print(\"✅ Training complete. Saved to\", OUTPUT_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OjKcLwAdDDl7",
        "outputId": "808ded3b-6a48-43d1-aa36-349d7e380e39"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing train_lora.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5 - confirm presence of files and script\n",
        "!ls -lh train.jsonl valid.jsonl train_lora.py || true\n",
        "!head -n 2 train.jsonl || true\n",
        "!head -n 2 valid.jsonl || true\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6NZyWOm2DGtO",
        "outputId": "1a98bbea-cf9b-4ed2-cf94-6bda93bd6785"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 385K Sep 15 11:03 train.jsonl\n",
            "-rw-r--r-- 1 root root 2.4K Sep 15 11:04 train_lora.py\n",
            "-rw-r--r-- 1 root root  43K Sep 15 11:03 valid.jsonl\n",
            "{\"prompt\": \"Instruction: Draft an email to a professor asking for a 3-day extension on an assignment due to illness. Include polite tone, class name, and mention you will submit by the new date.\", \"completion\": \"Subject: Request for 3-day extension on Biomechanics assignment\\n\\nDear Dr. Kapoor,\\n\\nI hope you are well. I am writing to request a 3-day extension for the homework for Biomechanics currently due on September 19, 2025. I have been unwell and, as a result, was unable to work on the assignment this week to the standard I aim for. I respectfully request permission to submit the homework by September 22, 2025. I assure you I will submit it by that date and complete it to the best of my ability.\\n\\nThank you for your understanding and consideration.\\n\\nSincerely,\\nNeha Roll No. 540552\\nBiomechanics\"}\n",
            "{\"prompt\": \"Instruction: Draft a polite email to request a recommendation letter from a professor for internship. Include timeline and proposed meeting.\", \"completion\": \"Subject: Request for Letter of Recommendation for Internship Application\\n\\nDear Professor Choudhary,\\n\\nI hope you are doing well. I am applying for an internship at Infosys and would be honored if you could write a letter of recommendation on my behalf. The application deadline is October 10, 2025. If possible, could we meet for 10–15 minutes to discuss my application and provide any details you may need? I am available on or after September 24, 2025, and I can adapt to a time that suits your schedule. I can also share my resume, transcript, and a brief summary of the internship role ahead of our meeting.\\n\\nThank you very much for considering my request. I appreciate any time you can spare.\\n\\nBest regards,\\nNeha\\nBTech, 3rd year\"}\n",
            "{\"prompt\": \"Instruction: Draft an email to a professor asking for a 3-day extension on an assignment due to illness. Include polite tone, class name, and mention you will submit by the new date.\", \"completion\": \"Subject: Request for 3-day extension on Signal Processing assignment\\n\\nDear Dr. Sharma,\\n\\nI hope you are well. I am writing to request a 3-day extension for the final deliverable for Signal Processing currently due on September 18, 2025. I have been unwell and, as a result, was unable to work on the assignment this week to the standard I aim for. I respectfully request permission to submit the final deliverable by September 21, 2025. I assure you I will submit it by that date and complete it to the best of my ability.\\n\\nThank you for your understanding and consideration.\\n\\nSincerely,\\nAarav Roll No. 407618\\nSignal Processing\"}\n",
            "{\"prompt\": \"Instruction: Draft an email to a professor asking for a 3-day extension on an assignment due to illness. Include polite tone, class name, and mention you will submit by the new date.\", \"completion\": \"Subject: Request for 3-day extension on Computer Networks assignment\\n\\nDear Dr. Sharma,\\n\\nI hope you are well. I am writing to request a 3-day extension for the lab report for Computer Networks currently due on September 22, 2025. I have been unwell and, as a result, was unable to work on the assignment this week to the standard I aim for. I respectfully request permission to submit the lab report by September 25, 2025. I assure you I will submit it by that date and complete it to the best of my ability.\\n\\nThank you for your understanding and consideration.\\n\\nSincerely,\\nMeera Roll No. 991014\\nComputer Networks\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6 - run training (explicit flags to force fp16)\n",
        "!accelerate launch --num_processes 1 --num_machines 1 --mixed_precision fp16 --dynamo_backend no train_lora.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GUpskgRwDXFH",
        "outputId": "3fc8cc23-d74b-48f9-92a6-ab4fa9d83e57"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-15 11:06:10.423283: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1757934370.462139    1885 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1757934370.473393    1885 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1757934370.500865    1885 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757934370.500921    1885 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757934370.500932    1885 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757934370.500939    1885 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Generating train split: 450 examples [00:00, 22323.85 examples/s]\n",
            "Generating validation split: 50 examples [00:00, 32493.83 examples/s]\n",
            "tokenizer_config.json: 100% 26.0/26.0 [00:00<00:00, 199kB/s]\n",
            "config.json: 100% 762/762 [00:00<00:00, 4.21MB/s]\n",
            "vocab.json: 100% 1.04M/1.04M [00:00<00:00, 1.63MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 2.10MB/s]\n",
            "tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 52.8MB/s]\n",
            "Map: 100% 450/450 [00:00<00:00, 962.51 examples/s]\n",
            "Map: 100% 50/50 [00:00<00:00, 837.37 examples/s]\n",
            "model.safetensors: 100% 353M/353M [00:09<00:00, 35.7MB/s]\n",
            "generation_config.json: 100% 124/124 [00:00<00:00, 690kB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/lora/layer.py:2174: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory. Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/offline-run-20250915_110740-v2fw45jn\u001b[0m\n",
            "  0% 0/171 [00:00<?, ?it/s]/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [224,0,0], thread: [64,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [224,0,0], thread: [65,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [224,0,0], thread: [66,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [224,0,0], thread: [67,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [224,0,0], thread: [68,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [224,0,0], thread: [69,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [224,0,0], thread: [70,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [224,0,0], thread: [71,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [224,0,0], thread: [72,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [224,0,0], thread: [73,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [224,0,0], thread: [74,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [224,0,0], thread: [75,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [224,0,0], thread: [76,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [224,0,0], thread: [77,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [224,0,0], thread: [78,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [224,0,0], thread: [79,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [224,0,0], thread: [80,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [224,0,0], thread: [81,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [224,0,0], thread: [82,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [224,0,0], thread: [83,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [224,0,0], thread: [84,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [224,0,0], thread: [85,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [224,0,0], thread: [86,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [224,0,0], thread: [87,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [224,0,0], thread: [88,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [224,0,0], thread: [89,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [224,0,0], thread: [90,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [224,0,0], thread: [91,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [224,0,0], thread: [92,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [224,0,0], thread: [93,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [224,0,0], thread: [94,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [224,0,0], thread: [95,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [96,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [97,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [98,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [99,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [100,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [101,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [102,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [103,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [104,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [105,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [106,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [107,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [108,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [109,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [110,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [111,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [112,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [113,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [114,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [115,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [116,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [117,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [118,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [119,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [120,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [121,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [122,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [123,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [124,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [125,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [126,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [127,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [64,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [65,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [66,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [67,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [68,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [69,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [70,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [71,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [72,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [73,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [74,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [75,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [76,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [77,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [78,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [79,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [80,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [81,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [82,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [83,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [84,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [85,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [86,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [87,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [88,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [89,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [90,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [91,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [92,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [93,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [94,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [95,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [32,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [33,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [34,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [35,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [36,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [37,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [38,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [39,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [40,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [41,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [42,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [43,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [44,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [45,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [46,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [47,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [48,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [49,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [50,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [51,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [52,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [53,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [54,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [55,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [56,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [57,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [58,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [59,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [60,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [61,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [62,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [200,0,0], thread: [63,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/train_lora.py\", line 68, in <module>\n",
            "    trainer.train()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\", line 2328, in train\n",
            "    return inner_training_loop(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\", line 2672, in _inner_training_loop\n",
            "    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\", line 4009, in training_step\n",
            "    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\", line 4099, in compute_loss\n",
            "    outputs = model(**inputs)\n",
            "              ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py\", line 818, in forward\n",
            "    return model_forward(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py\", line 806, in __call__\n",
            "    return convert_to_fp32(self.model_forward(*args, **kwargs))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/amp/autocast_mode.py\", line 44, in decorate_autocast\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/peft/peft_model.py\", line 1850, in forward\n",
            "    return self.base_model(\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py\", line 222, in forward\n",
            "    return self.model.forward(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/gpt2/modeling_gpt2.py\", line 1070, in forward\n",
            "    transformer_outputs = self.transformer(\n",
            "                          ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/gpt2/modeling_gpt2.py\", line 861, in forward\n",
            "    cache_position = torch.arange(\n",
            "                     ^^^^^^^^^^^^^\n",
            "torch.AcceleratorError: CUDA error: device-side assert triggered\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[1;34mwandb\u001b[0m: \u001b[1mwandb sync /content/wandb/offline-run-20250915_110740-v2fw45jn\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/offline-run-20250915_110740-v2fw45jn/logs\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/commands/accelerate_cli.py\", line 50, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/commands/launch.py\", line 1235, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/commands/launch.py\", line 823, in simple_launcher\n",
            "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', 'train_lora.py']' returned non-zero exit status 1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommended: normal run (no synchronous CUDA debugging)\n",
        "!WANDB_MODE=disabled accelerate launch --num_processes 1 --num_machines 1 --mixed_precision fp16 --dynamo_backend no train_lora.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_FpcgIm0EVeT",
        "outputId": "7f55fa5b-a61e-4f6b-e147-f0d48b435bbf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-15 11:10:52.299379: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1757934652.320848    3119 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1757934652.327012    3119 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1757934652.342812    3119 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757934652.342835    3119 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757934652.342839    3119 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757934652.342844    3119 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Map: 100% 450/450 [00:00<00:00, 834.88 examples/s]\n",
            "Map: 100% 50/50 [00:00<00:00, 786.96 examples/s]\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/lora/layer.py:2174: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
            "  warnings.warn(\n",
            "  0% 0/171 [00:00<?, ?it/s]`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n",
            "{'loss': 3.2614, 'grad_norm': 0.987451434135437, 'learning_rate': 0.00014269005847953217, 'epoch': 0.89}\n",
            "{'loss': 2.3087, 'grad_norm': 1.4436091184616089, 'learning_rate': 8.421052631578948e-05, 'epoch': 1.76}\n",
            "{'loss': 1.7923, 'grad_norm': 1.8046194314956665, 'learning_rate': 2.5730994152046783e-05, 'epoch': 2.64}\n",
            " 99% 170/171 [00:42<00:00,  4.10it/s]/usr/local/lib/python3.12/dist-packages/peft/utils/save_and_load.py:300: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "{'train_runtime': 46.6054, 'train_samples_per_second': 28.967, 'train_steps_per_second': 3.669, 'train_loss': 2.356355566727488, 'epoch': 3.0}\n",
            "100% 171/171 [00:46<00:00,  3.67it/s]\n",
            "Running evaluation on validation set...\n",
            "100% 25/25 [00:00<00:00, 30.78it/s]\n",
            "Evaluation metrics: {'eval_loss': 1.2628819942474365, 'eval_runtime': 0.8326, 'eval_samples_per_second': 60.052, 'eval_steps_per_second': 30.026, 'epoch': 3.0}\n",
            "/usr/local/lib/python3.12/dist-packages/peft/utils/save_and_load.py:300: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "✅ Training complete. Model and adapter saved to lora-output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell: load tokenizer, resize base embeddings, then load PEFT adapter\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "import torch\n",
        "\n",
        "MODEL_NAME = \"distilgpt2\"\n",
        "ADAPTER_DIR = \"lora-output\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# load tokenizer from the adapter folder (this has the added pad token)\n",
        "tokenizer = AutoTokenizer.from_pretrained(ADAPTER_DIR)\n",
        "\n",
        "# load base model\n",
        "base = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# resize base embeddings to match tokenizer length (important!)\n",
        "if base.get_input_embeddings().weight.size(0) != len(tokenizer):\n",
        "    print(\"Resizing base embeddings from\", base.get_input_embeddings().weight.size(0), \"to\", len(tokenizer))\n",
        "    base.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# now load the peft adapter onto the resized base\n",
        "model = PeftModel.from_pretrained(base, ADAPTER_DIR)\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# quick generation function\n",
        "def draft_email(prompt, max_new_tokens=200, temperature=0.7):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    out = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=True,\n",
        "        top_p=0.95,\n",
        "        temperature=temperature,\n",
        "        pad_token_id=tokenizer.pad_token_id\n",
        "    )\n",
        "    # remove prompt part from generated output\n",
        "    gen = tokenizer.decode(out[0][inputs['input_ids'].shape[-1]:], skip_special_tokens=True)\n",
        "    return gen\n",
        "\n",
        "# test\n",
        "prompt = \"Instruction: Draft a polite email requesting a 3-day extension for an assignment due to illness.\\n\\n###\\n\"\n",
        "print(draft_email(prompt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "eaGieTmLE-Dj",
        "outputId": "73b6ae2b-2405-489e-9f4f-ee27f3327ca6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resizing base embeddings from 50257 to 50258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dear Dr. Lasson,\n",
            "\n",
            "\n",
            "I would like to extend my request for an internship at Microsoft. I am currently writing a letter to Dr. Lasson on behalf of my research project and would be honored if it could be transcribed. I am extremely honored to be able to work on my project and could write it on your behalf.\n",
            "\n",
            "Thank you for taking this opportunity to transcribe my research and write it on my behalf.\n",
            "\n",
            "Sincerely,\n",
            "\n",
            "\n",
            "Sharon\n",
            "Associate Professor\n",
            "Microsoft Research\n",
            "\n",
            "17.09.2014\n",
            "Dear Dr. Lasson,\n",
            "I appreciate your consideration and interest in transcribing my research. I appreciate your interest in transcribing my research and would be honored if it could be transcribed.\n",
            "\n",
            "Thank you for understanding and consideration of transcribing my research and I hope you can contribute to my research.\n",
            "\n",
            "\n",
            "Thank you for your understanding and consideration of transcribing my research and I hope you can\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def draft_email(prompt, max_new_tokens=200, temperature=0.7):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    out = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=True,\n",
        "        top_p=0.9,                # nucleus sampling, avoids nonsense\n",
        "        temperature=temperature,  # controls creativity\n",
        "        repetition_penalty=1.3,   # reduces repetition\n",
        "        no_repeat_ngram_size=3,   # blocks repeated phrases\n",
        "        pad_token_id=tokenizer.pad_token_id\n",
        "    )\n",
        "    gen = tokenizer.decode(out[0][inputs['input_ids'].shape[-1]:], skip_special_tokens=True)\n",
        "    return gen\n",
        "\n",
        "# test again\n",
        "prompt = \"Instruction: Draft a polite email requesting a 3-day extension for an assignment due to illness.\\n\\n###\\n\"\n",
        "print(draft_email(prompt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "tSNx_MgEF0Oo",
        "outputId": "f93a5f6c-16e0-4acc-ac28-8282a696493c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dear Dr. Roshan Sharma,\n",
            "\n",
            "I am currently writing letter of intent on receiving the application by completing my online research course at Google Engineering in 2015 and applying it as I planned with time until October 20 . We appreciate your understanding about our request and would share any information you may have regarding this decision without further comment or word. While we are studying engineering from 2013 to 2014, please consider sharing if possible—we hope that helps us become even more productive when pursuing such assignments once again!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def draft_email(prompt, max_new_tokens=200, temperature=0.7):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    out = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=True,\n",
        "        top_p=0.9,                 # nucleus sampling\n",
        "        temperature=temperature,   # creativity control\n",
        "        repetition_penalty=1.3,    # reduce loops\n",
        "        no_repeat_ngram_size=4,    # stricter: avoid repeating 4-word chunks\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "        eos_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    gen = tokenizer.decode(out[0][inputs['input_ids'].shape[-1]:], skip_special_tokens=True)\n",
        "\n",
        "    # 🧹 Cleanup: stop after common polite endings\n",
        "    for stop in [\"Sincerely\", \"Best regards\", \"Regards\", \"Thank you\"]:\n",
        "        if stop in gen:\n",
        "            gen = gen.split(stop)[0] + stop\n",
        "            break\n",
        "\n",
        "    return gen.strip()\n",
        "\n",
        "# Example test\n",
        "prompt = \"\"\"Instruction: Draft a polite email to a professor requesting\n",
        "a 3-day extension for the \"Computer Networks\" assignment due to illness.\n",
        "The email should include: subject line, greeting, explanation, new submission date, and a polite closing.\n",
        "\"\"\"\n",
        "print(draft_email(prompt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qtBIchupHccl",
        "outputId": "37e16a68-4ae8-455f-8d0a-91a62e3e17c2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subject Line 57521 - Computer Network Needs Attention! Write an application letter outlining how you can apply online by July 7th at 9 am PST using current computer networks on your behalf in Los Angeles as they are currently scheduled or will be published next week based upon our recommendation of best course level while we meet all possible deadlines during that time period so everyone who would like to submit their resume electronically is invited immediately thereafter if feasible with any additional information needed before submitting it here.\"\n",
            "Dear Dr. Bao, Thank You For Your Service; I appreciate every effort made toward completing this project within three months without delay nor hesitation when proposing such work forward through my full potential beyond just one month until completion has been complete,\" wrote me after receiving faxed request from ATSB's office today afternoon evening (September 10) seeking input regarding applications submitted directly ahead thereof under consideration of appropriate standard practice set forth herein.]\n",
            "Thankyou, My Name Is Maximalized In lieu Of Any Requests We Can Submit To\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!WANDB_MODE=disabled accelerate launch --num_processes 1 --num_machines 1 --mixed_precision fp16 train_lora.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "baMopHbZIZaL",
        "outputId": "9358ea67-d581-4423-eef7-b402e12ad097"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-09-15 11:28:31.716594: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1757935711.737815    7588 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1757935711.744115    7588 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1757935711.760870    7588 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757935711.760895    7588 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757935711.760900    7588 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757935711.760904    7588 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "tokenizer_config.json: 100% 26.0/26.0 [00:00<00:00, 205kB/s]\n",
            "config.json: 100% 718/718 [00:00<00:00, 5.27MB/s]\n",
            "vocab.json: 100% 1.04M/1.04M [00:00<00:00, 4.63MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 17.4MB/s]\n",
            "tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 6.07MB/s]\n",
            "Map: 100% 450/450 [00:00<00:00, 1597.67 examples/s]\n",
            "Map: 100% 50/50 [00:00<00:00, 1451.64 examples/s]\n",
            "Loading base model gpt2-medium ...\n",
            "model.safetensors: 100% 1.52G/1.52G [01:22<00:00, 18.4MB/s]\n",
            "generation_config.json: 100% 124/124 [00:00<00:00, 1.11MB/s]\n",
            "Resizing token embeddings from 50257 to 50258\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/lora/layer.py:2174: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
            "  warnings.warn(\n",
            "  0% 0/342 [00:00<?, ?it/s]`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n",
            "{'loss': 2.265, 'grad_norm': 1.040213704109192, 'learning_rate': 0.0001713450292397661, 'epoch': 0.89}\n",
            "{'loss': 0.6877, 'grad_norm': 1.1364747285842896, 'learning_rate': 0.00014210526315789474, 'epoch': 1.76}\n",
            "{'loss': 0.3023, 'grad_norm': 0.653308093547821, 'learning_rate': 0.0001128654970760234, 'epoch': 2.64}\n",
            "{'loss': 0.2187, 'grad_norm': 0.7628026604652405, 'learning_rate': 8.362573099415205e-05, 'epoch': 3.52}\n",
            "{'loss': 0.1935, 'grad_norm': 0.6510153412818909, 'learning_rate': 5.438596491228071e-05, 'epoch': 4.39}\n",
            "{'loss': 0.1861, 'grad_norm': 0.6926597952842712, 'learning_rate': 2.5146198830409358e-05, 'epoch': 5.27}\n",
            "100% 342/342 [04:32<00:00,  1.54it/s]/usr/local/lib/python3.12/dist-packages/peft/utils/save_and_load.py:300: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "{'train_runtime': 290.444, 'train_samples_per_second': 9.296, 'train_steps_per_second': 1.178, 'train_loss': 0.5846963946582281, 'epoch': 6.0}\n",
            "100% 342/342 [04:50<00:00,  1.18it/s]\n",
            "Running evaluation on validation set...\n",
            "100% 50/50 [00:02<00:00, 20.90it/s]\n",
            "Evaluation metrics: {'eval_loss': 0.14017276465892792, 'eval_runtime': 2.4384, 'eval_samples_per_second': 20.505, 'eval_steps_per_second': 20.505, 'epoch': 6.0}\n",
            "/usr/local/lib/python3.12/dist-packages/peft/utils/save_and_load.py:300: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "✅ Training complete. Model and adapter saved to lora-output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell: load tokenizer, resize base embeddings, then load PEFT adapter + inference\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "import torch, os\n",
        "\n",
        "MODEL_NAME = \"gpt2-medium\"\n",
        "ADAPTER_DIR = \"lora-output\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# 1) load tokenizer from adapter (this contains the pad token added during training)\n",
        "tokenizer = AutoTokenizer.from_pretrained(ADAPTER_DIR)\n",
        "print(\"Tokenizer length:\", len(tokenizer))\n",
        "\n",
        "# 2) load base model\n",
        "base = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
        "print(\"Base embedding size before resize:\", base.get_input_embeddings().weight.size(0))\n",
        "\n",
        "# 3) resize base embeddings if needed\n",
        "if base.get_input_embeddings().weight.size(0) != len(tokenizer):\n",
        "    print(\"Resizing base embeddings to match tokenizer length...\")\n",
        "    base.resize_token_embeddings(len(tokenizer))\n",
        "    print(\"Base embedding size after resize:\", base.get_input_embeddings().weight.size(0))\n",
        "else:\n",
        "    print(\"No resize needed.\")\n",
        "\n",
        "# 4) now load the PEFT adapter onto the resized base\n",
        "model = PeftModel.from_pretrained(base, ADAPTER_DIR).to(device)\n",
        "model.eval()\n",
        "print(\"Adapter loaded successfully. Model on device:\", device)\n",
        "\n",
        "# ====== Improved generation function (stricter + cleanup) ======\n",
        "def draft_email(prompt, max_new_tokens=200, temperature=0.6):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    out = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=True,\n",
        "        top_p=0.9,\n",
        "        temperature=temperature,\n",
        "        repetition_penalty=1.5,\n",
        "        no_repeat_ngram_size=4,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "        eos_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    gen = tokenizer.decode(out[0][inputs['input_ids'].shape[-1]:], skip_special_tokens=True)\n",
        "\n",
        "    # stop at common polite endings\n",
        "    for stop in [\"Sincerely\", \"Best regards\", \"Regards\", \"Thank you\"]:\n",
        "        if stop in gen:\n",
        "            gen = gen.split(stop)[0] + stop\n",
        "            break\n",
        "\n",
        "    # keep only first 3 paragraphs\n",
        "    gen = \"\\n\\n\".join(gen.split(\"\\n\\n\")[:3])\n",
        "    return gen.strip()\n",
        "\n",
        "# ====== Quick test prompt ======\n",
        "prompt = \"\"\"\n",
        "Instruction: Draft a formal email to Professor Singh requesting a 3-day extension\n",
        "for the \"Computer Networks\" assignment due to illness.\n",
        "The email must include: Subject line, greeting, reason (illness), clear request for extension, new submission date (September 21, 2025), and polite closing.\n",
        "\"\"\"\n",
        "print(draft_email(prompt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "maZeYs0xKbNV",
        "outputId": "58b8d896-3324-47e7-cfeb-2242de69c6c9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer length: 50258\n",
            "Base embedding size before resize: 50257\n",
            "Resizing base embeddings to match tokenizer length...\n",
            "Base embedding size after resize: 50258\n",
            "Adapter loaded successfully. Model on device: cuda\n",
            "Dear Dr. Sharma, I hope you are well. My name is Ravi and I am applying on behalf of my graduate student application asking if possible an extension this week so that we can complete our work on computer networks together! I have been unwell since September 17th & 18 th and currently have no timeline beyond 10–15 minutes to submit your application. If possible, could we meet in person on September 19 , 20 or 22 to discuss how best we may help each other achieve final grade on time? I assure everyone we will be respectful towards each others' busy schedules.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deterministic beam decode + post-cleanup\n",
        "import re\n",
        "\n",
        "def sanitize_text(text):\n",
        "    # Remove weird repeated punctuation/phrasing and fix spacing\n",
        "    text = re.sub(r'\\s+([,\\.])', r'\\1', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    # Remove multiple repeated phrases (simple heuristic)\n",
        "    text = re.sub(r'(\\b\\w+\\b)(?:\\s+\\1){2,}', r'\\1', text)\n",
        "    return text\n",
        "\n",
        "def build_strict_prompt(professor=\"Professor Singh\", course=\"Computer Networks\", due=\"September 18, 2025\", new_date=\"September 21, 2025\"):\n",
        "    return (\n",
        "        f\"Instruction: Write a **short, formal** email from a single student to {professor}. \"\n",
        "        f\"The student is requesting a 3-day extension for the \\\"{course}\\\" assignment because of illness. \"\n",
        "        \"Include exactly: Subject line, Greeting, One short paragraph stating the reason, One line requesting a 3-day extension and the exact new submission date, and a polite closing. \"\n",
        "        \"Avoid mentioning other organizations, previous years, or locations. Use first-person singular only (I, my).\"\n",
        "        f\"\\n\\nNew submission date: {new_date}\\n\\n\"\n",
        "    )\n",
        "\n",
        "def draft_email_beam(prompt, max_new_tokens=150, num_beams=4):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    out = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=False,            # deterministic\n",
        "        num_beams=num_beams,\n",
        "        early_stopping=True,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        no_repeat_ngram_size=3\n",
        "    )\n",
        "    gen = tokenizer.decode(out[0][inputs['input_ids'].shape[-1]:], skip_special_tokens=True)\n",
        "    gen = sanitize_text(gen)\n",
        "\n",
        "    # Ensure required elements present, otherwise fall back to template\n",
        "    if (\"extension\" not in gen.lower() or \"submit\" not in gen.lower()) or len(gen.split()) < 30:\n",
        "        # fallback template (very safe)\n",
        "        template = (\n",
        "            f\"Subject: Request for 3-Day Extension on {course} Assignment\\n\\n\"\n",
        "            f\"Dear {professor},\\n\\n\"\n",
        "            \"I hope you are well. I have been ill and could not complete the assignment by the deadline. \"\n",
        "            f\"I respectfully request a 3-day extension and will submit the assignment by {new_date}.\\n\\n\"\n",
        "            \"Thank you for your understanding.\\n\\nSincerely,\\n[Your Name]\"\n",
        "        )\n",
        "        return template\n",
        "    return gen\n",
        "\n",
        "# Example usage:\n",
        "professor = \"Professor Singh\"\n",
        "course = \"Computer Networks\"\n",
        "new_date = \"September 21, 2025\"\n",
        "prompt = build_strict_prompt(professor=professor, course=course, new_date=new_date)\n",
        "print(draft_email_beam(prompt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jOOrtuveLy4J",
        "outputId": "fb238dcf-e804-4114-c070-123f1b3c5df8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subject: Request for 3-Day Extension on Computer Networks Assignment\n",
            "\n",
            "Dear Professor Singh,\n",
            "\n",
            "I hope you are well. I have been ill and could not complete the assignment by the deadline. I respectfully request a 3-day extension and will submit the assignment by September 21, 2025.\n",
            "\n",
            "Thank you for your understanding.\n",
            "\n",
            "Sincerely,\n",
            "[Your Name]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random, json\n",
        "\n",
        "# Parameters\n",
        "TRAIN_SIZE = 2000\n",
        "VALID_SIZE = 200\n",
        "OUTPUT_TRAIN = \"train_v2.jsonl\"\n",
        "OUTPUT_VALID = \"valid_v2.jsonl\"\n",
        "\n",
        "# Sample data pools (expanded)\n",
        "professors = [\n",
        "    \"Dr. Sharma\", \"Prof. Singh\", \"Dr. Mehta\", \"Prof. Kapoor\", \"Dr. Rao\", \"Prof. Chatterjee\",\n",
        "    \"Dr. Iyer\", \"Prof. Banerjee\", \"Dr. Nair\", \"Prof. Pillai\", \"Dr. Joshi\", \"Prof. Das\",\n",
        "    \"Dr. Verma\", \"Prof. Kulkarni\", \"Dr. Menon\", \"Prof. Bhatia\", \"Dr. Mukherjee\", \"Prof. Reddy\"\n",
        "]\n",
        "\n",
        "courses = [\n",
        "    \"Computer Networks\", \"Signal Processing\", \"Data Structures\", \"Machine Learning\",\n",
        "    \"Bioinformatics\", \"Operating Systems\", \"Artificial Intelligence\", \"Database Systems\",\n",
        "    \"Software Engineering\", \"Compiler Design\", \"Digital Logic Design\", \"Embedded Systems\",\n",
        "    \"Algorithms\", \"Probability & Statistics\", \"Cloud Computing\", \"Cybersecurity\",\n",
        "    \"Parallel Computing\", \"Natural Language Processing\"\n",
        "]\n",
        "\n",
        "dates = [\n",
        "    \"September 18, 2025\", \"September 20, 2025\", \"September 21, 2025\", \"September 25, 2025\",\n",
        "    \"October 1, 2025\", \"October 5, 2025\", \"October 10, 2025\", \"October 15, 2025\",\n",
        "    \"October 20, 2025\", \"October 25, 2025\", \"November 1, 2025\", \"November 5, 2025\",\n",
        "    \"November 10, 2025\", \"November 15, 2025\", \"November 20, 2025\"\n",
        "]\n",
        "\n",
        "# Templates (diverse instructions)\n",
        "templates = [\n",
        "    {\n",
        "        \"prompt\": \"Instruction: Draft an email to {professor} asking for a 3-day extension on the {course} assignment due to illness. Include subject line, greeting, reason, new submission date {date}, and polite closing.\",\n",
        "        \"completion\": \"Subject: Request for 3-Day Extension on {course} Assignment\\n\\nDear {professor},\\n\\nI hope you are well. I have been unwell and was unable to complete the {course} assignment by the original deadline. I respectfully request a 3-day extension and assure you that I will submit it by {date}.\\n\\nThank you for your understanding.\\n\\nSincerely,\\n[Your Name]\"\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": \"Instruction: Write a polite email to {professor} requesting a letter of recommendation for an internship. Include subject line, greeting, purpose, deadline {date}, and polite closing.\",\n",
        "        \"completion\": \"Subject: Request for Recommendation Letter\\n\\nDear {professor},\\n\\nI hope you are doing well. I am applying for an internship and would be grateful if you could provide a recommendation letter for me. The application deadline is {date}. I would be happy to share my resume and details of the position for your reference.\\n\\nThank you for considering my request.\\n\\nBest regards,\\n[Your Name]\"\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": \"Instruction: Write a formal email to {professor} requesting leave of absence from class. Include subject line, greeting, reason (illness/family emergency), date {date}, and polite closing.\",\n",
        "        \"completion\": \"Subject: Request for Leave of Absence\\n\\nDear {professor},\\n\\nI am writing to request leave from class due to personal reasons. I kindly ask for your permission to be absent until {date}. I will ensure to cover the missed material promptly.\\n\\nThank you for your understanding.\\n\\nRegards,\\n[Your Name]\"\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": \"Instruction: Write a polite email to {professor} asking for clarification on a {course} assignment. Include subject line, greeting, your question, reference to deadline {date}, and polite closing.\",\n",
        "        \"completion\": \"Subject: Clarification on {course} Assignment\\n\\nDear {professor},\\n\\nI hope you are doing well. I am seeking clarification regarding the recent {course} assignment due by {date}. Could you please confirm whether we are expected to include both the theoretical explanation and code implementation?\\n\\nThank you for your guidance.\\n\\nSincerely,\\n[Your Name]\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Function to fill templates with random values\n",
        "def make_example():\n",
        "    t = random.choice(templates)\n",
        "    professor = random.choice(professors)\n",
        "    course = random.choice(courses)\n",
        "    date = random.choice(dates)\n",
        "    prompt = t[\"prompt\"].format(professor=professor, course=course, date=date)\n",
        "    completion = t[\"completion\"].format(professor=professor, course=course, date=date)\n",
        "    return {\"prompt\": prompt, \"completion\": completion}\n",
        "\n",
        "# Generate train + valid\n",
        "train_data = [make_example() for _ in range(TRAIN_SIZE)]\n",
        "valid_data = [make_example() for _ in range(VALID_SIZE)]\n",
        "\n",
        "# Save to JSONL\n",
        "with open(OUTPUT_TRAIN, \"w\") as f:\n",
        "    for ex in train_data:\n",
        "        f.write(json.dumps(ex) + \"\\n\")\n",
        "\n",
        "with open(OUTPUT_VALID, \"w\") as f:\n",
        "    for ex in valid_data:\n",
        "        f.write(json.dumps(ex) + \"\\n\")\n",
        "\n",
        "print(f\"✅ Generated {TRAIN_SIZE} training and {VALID_SIZE} validation examples.\")\n",
        "print(f\"Saved as {OUTPUT_TRAIN} and {OUTPUT_VALID}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "DHK-9fIVObXj",
        "outputId": "8c49fe77-2104-4d92-a38a-7ceac1db40db"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Generated 2000 training and 200 validation examples.\n",
            "Saved as train_v2.jsonl and valid_v2.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!WANDB_MODE=disabled accelerate launch --num_processes 1 --num_machines 1 --mixed_precision fp16 train_lora.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "slEGk0hzPPcS",
        "outputId": "fc3d0398-7599-433c-e23e-bfdd0bc6950c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-09-15 11:58:21.334726: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1757937501.355880   15049 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1757937501.362309   15049 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1757937501.380445   15049 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757937501.380475   15049 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757937501.380479   15049 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757937501.380485   15049 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Generating train split: 2000 examples [00:00, 93023.81 examples/s]\n",
            "Generating validation split: 200 examples [00:00, 114535.88 examples/s]\n",
            "Map: 100% 2000/2000 [00:01<00:00, 1780.24 examples/s]\n",
            "Map: 100% 200/200 [00:00<00:00, 1808.70 examples/s]\n",
            "Loading base model gpt2-medium ...\n",
            "Resizing token embeddings from 50257 to 50258\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/lora/layer.py:2174: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
            "  warnings.warn(\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/train_lora.py\", line 69, in <module>\n",
            "    training_args = TrainingArguments(\n",
            "                    ^^^^^^^^^^^^^^^^^^\n",
            "TypeError: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/commands/accelerate_cli.py\", line 50, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/commands/launch.py\", line 1235, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/commands/launch.py\", line 823, in simple_launcher\n",
            "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', 'train_lora.py']' returned non-zero exit status 1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train_lora.py\n",
        "import os\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
        "from peft import LoraConfig, get_peft_model\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# ===== Configuration - edit if needed =====\n",
        "MODEL_NAME = \"gpt2-medium\"   # switched from distilgpt2 -> gpt2-medium\n",
        "OUTPUT_DIR = \"lora-output\"\n",
        "TRAIN_FILE = \"train_v2.jsonl\"\n",
        "VALID_FILE = \"valid_v2.jsonl\"\n",
        "BATCH_SIZE = 1               # lower to fit gpt2-medium on 8GB\n",
        "EPOCHS = 8                   # increased from 3 -> 6\n",
        "MAX_LENGTH = 512             # reduce context to save memory\n",
        "GRADIENT_ACCUM_STEPS = 8     # accumulate grads to simulate larger batch\n",
        "LEARNING_RATE = 2e-4\n",
        "# ==========================================\n",
        "\n",
        "if not (os.path.exists(TRAIN_FILE) and os.path.exists(VALID_FILE)):\n",
        "    raise FileNotFoundError(\"Please upload train.jsonl and valid.jsonl into Colab working dir.\")\n",
        "\n",
        "# Load dataset\n",
        "dataset = load_dataset(\"json\", data_files={\"train\": TRAIN_FILE, \"validation\": VALID_FILE})\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "\n",
        "# Preprocess: encode prompt+completion together as input; labels = input_ids with pad -> -100\n",
        "def preprocess_batch(batch):\n",
        "    texts = [p + c for p, c in zip(batch[\"prompt\"], batch[\"completion\"])]\n",
        "    enc = tokenizer(texts, truncation=True, padding=\"max_length\", max_length=MAX_LENGTH)\n",
        "    input_ids = enc[\"input_ids\"]\n",
        "    attention_mask = enc[\"attention_mask\"]\n",
        "    # labels: copy of input_ids, but replace pad_token_id with -100 so loss ignores them\n",
        "    pad_id = tokenizer.pad_token_id\n",
        "    labels = []\n",
        "    for ids in input_ids:\n",
        "        lab = [(i if i != pad_id else -100) for i in ids]\n",
        "        labels.append(lab)\n",
        "    enc[\"labels\"] = labels\n",
        "    return enc\n",
        "\n",
        "tokenized = dataset.map(preprocess_batch, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
        "\n",
        "# Data collator: simple collator (already padded)\n",
        "def collate_fn(batch):\n",
        "    # batch is list of dicts with input_ids, attention_mask, labels\n",
        "    input_ids = torch.tensor([b[\"input_ids\"] for b in batch], dtype=torch.long)\n",
        "    attention_mask = torch.tensor([b[\"attention_mask\"] for b in batch], dtype=torch.long)\n",
        "    labels = torch.tensor([b[\"labels\"] for b in batch], dtype=torch.long)\n",
        "    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": labels}\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load base model\n",
        "print(f\"Loading base model {MODEL_NAME} ...\")\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
        "# If tokenizer length changed (we added pad token), resize token embeddings\n",
        "if model.get_input_embeddings().weight.size(0) != len(tokenizer):\n",
        "    print(\"Resizing token embeddings from\", model.get_input_embeddings().weight.size(0), \"to\", len(tokenizer))\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# Attach LoRA (parameter-efficient)\n",
        "lora_config = LoraConfig(r=8, lora_alpha=32, lora_dropout=0.1, bias=\"none\", task_type=\"CAUSAL_LM\")\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "# Training arguments (minimal, with disabled reporting)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    gradient_accumulation_steps=GRADIENT_ACCUM_STEPS,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    logging_steps=50,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    fp16=True,\n",
        "    save_total_limit=2,\n",
        "    report_to=[\"none\"],\n",
        "    eval_steps=200,     # run evaluation every 200 steps\n",
        "    save_steps=200,     # save checkpoint every 200 steps\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized[\"train\"],\n",
        "    eval_dataset=tokenized[\"validation\"],\n",
        "    data_collator=collate_fn,\n",
        ")\n",
        "\n",
        "# Train\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate explicitly\n",
        "print(\"Running evaluation on validation set...\")\n",
        "metrics = trainer.evaluate(eval_dataset=tokenized[\"validation\"])\n",
        "print(\"Evaluation metrics:\", metrics)\n",
        "\n",
        "# Save adapter + tokenizer\n",
        "model.save_pretrained(OUTPUT_DIR)\n",
        "tokenizer.save_pretrained(OUTPUT_DIR)\n",
        "print(\"✅ Training complete. Model and adapter saved to\", OUTPUT_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bVP6jm4QERhJ",
        "outputId": "40b19bab-ac47-41f6-f9a2-67212037fb40"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting train_lora.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!WANDB_MODE=disabled accelerate launch --num_processes 1 --num_machines 1 --mixed_precision fp16 train_lora.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9pRf6iqaQT82",
        "outputId": "83009b61-2ef9-4c0c-8cba-ddace0d5faef"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-09-15 12:02:58.605526: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1757937778.626108   16238 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1757937778.632746   16238 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1757937778.648325   16238 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757937778.648353   16238 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757937778.648365   16238 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757937778.648372   16238 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Map: 100% 2000/2000 [00:01<00:00, 1827.14 examples/s]\n",
            "Map: 100% 200/200 [00:00<00:00, 1761.45 examples/s]\n",
            "Loading base model gpt2-medium ...\n",
            "Resizing token embeddings from 50257 to 50258\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/lora/layer.py:2174: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
            "  warnings.warn(\n",
            "  0% 0/2000 [00:00<?, ?it/s]`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n",
            "{'loss': 1.9644, 'grad_norm': 1.4808636903762817, 'learning_rate': 0.00019510000000000003, 'epoch': 0.2}\n",
            "{'loss': 0.5262, 'grad_norm': 0.8834877610206604, 'learning_rate': 0.0001901, 'epoch': 0.4}\n",
            "{'loss': 0.2245, 'grad_norm': 0.8641476035118103, 'learning_rate': 0.0001851, 'epoch': 0.6}\n",
            "{'loss': 0.1591, 'grad_norm': 0.5853253602981567, 'learning_rate': 0.00018010000000000001, 'epoch': 0.8}\n",
            " 10% 200/2000 [03:31<30:03,  1.00s/it]/usr/local/lib/python3.12/dist-packages/peft/utils/save_and_load.py:300: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "{'loss': 0.1274, 'grad_norm': 0.9183789491653442, 'learning_rate': 0.0001751, 'epoch': 1.0}\n",
            "{'loss': 0.1151, 'grad_norm': 0.506868302822113, 'learning_rate': 0.00017010000000000001, 'epoch': 1.2}\n",
            "{'loss': 0.1041, 'grad_norm': 0.566752016544342, 'learning_rate': 0.0001651, 'epoch': 1.4}\n",
            "{'loss': 0.0986, 'grad_norm': 0.3313520848751068, 'learning_rate': 0.00016010000000000002, 'epoch': 1.6}\n",
            " 20% 400/2000 [07:11<26:34,  1.00it/s]/usr/local/lib/python3.12/dist-packages/peft/utils/save_and_load.py:300: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0962, 'grad_norm': 0.5022799968719482, 'learning_rate': 0.0001551, 'epoch': 1.8}\n",
            "{'loss': 0.0933, 'grad_norm': 0.37428608536720276, 'learning_rate': 0.0001501, 'epoch': 2.0}\n",
            "{'loss': 0.0903, 'grad_norm': 0.41413694620132446, 'learning_rate': 0.0001451, 'epoch': 2.2}\n",
            "{'loss': 0.0872, 'grad_norm': 0.36167722940444946, 'learning_rate': 0.00014010000000000002, 'epoch': 2.4}\n",
            " 30% 600/2000 [10:50<23:18,  1.00it/s]/usr/local/lib/python3.12/dist-packages/peft/utils/save_and_load.py:300: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0852, 'grad_norm': 0.32330310344696045, 'learning_rate': 0.0001351, 'epoch': 2.6}\n",
            "{'loss': 0.0857, 'grad_norm': 0.36233633756637573, 'learning_rate': 0.0001301, 'epoch': 2.8}\n",
            "{'loss': 0.0873, 'grad_norm': 0.3409344255924225, 'learning_rate': 0.0001251, 'epoch': 3.0}\n",
            "{'loss': 0.0837, 'grad_norm': 0.36789625883102417, 'learning_rate': 0.00012010000000000002, 'epoch': 3.2}\n",
            " 40% 800/2000 [14:23<20:30,  1.03s/it]/usr/local/lib/python3.12/dist-packages/peft/utils/save_and_load.py:300: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0822, 'grad_norm': 0.2905009686946869, 'learning_rate': 0.0001151, 'epoch': 3.4}\n",
            "{'loss': 0.0821, 'grad_norm': 0.28471606969833374, 'learning_rate': 0.0001101, 'epoch': 3.6}\n",
            "{'loss': 0.0817, 'grad_norm': 0.2874712347984314, 'learning_rate': 0.0001051, 'epoch': 3.8}\n",
            "{'loss': 0.0814, 'grad_norm': 0.3004458248615265, 'learning_rate': 0.0001001, 'epoch': 4.0}\n",
            " 50% 1000/2000 [18:02<16:40,  1.00s/it]/usr/local/lib/python3.12/dist-packages/peft/utils/save_and_load.py:300: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0813, 'grad_norm': 0.32907938957214355, 'learning_rate': 9.51e-05, 'epoch': 4.2}\n",
            "{'loss': 0.0814, 'grad_norm': 0.26649826765060425, 'learning_rate': 9.010000000000001e-05, 'epoch': 4.4}\n",
            "{'loss': 0.0795, 'grad_norm': 0.3005668818950653, 'learning_rate': 8.510000000000001e-05, 'epoch': 4.6}\n",
            "{'loss': 0.0782, 'grad_norm': 0.2649041414260864, 'learning_rate': 8.010000000000001e-05, 'epoch': 4.8}\n",
            " 60% 1200/2000 [21:42<13:16,  1.00it/s]/usr/local/lib/python3.12/dist-packages/peft/utils/save_and_load.py:300: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0776, 'grad_norm': 0.35591939091682434, 'learning_rate': 7.510000000000001e-05, 'epoch': 5.0}\n",
            "{'loss': 0.0773, 'grad_norm': 0.24449516832828522, 'learning_rate': 7.01e-05, 'epoch': 5.2}\n",
            "{'loss': 0.0789, 'grad_norm': 0.2896275222301483, 'learning_rate': 6.510000000000001e-05, 'epoch': 5.4}\n",
            "{'loss': 0.0779, 'grad_norm': 0.3196776211261749, 'learning_rate': 6.0100000000000004e-05, 'epoch': 5.6}\n",
            " 70% 1400/2000 [25:16<10:08,  1.01s/it]/usr/local/lib/python3.12/dist-packages/peft/utils/save_and_load.py:300: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0767, 'grad_norm': 0.2619326114654541, 'learning_rate': 5.5100000000000004e-05, 'epoch': 5.8}\n",
            "{'loss': 0.0776, 'grad_norm': 0.3013800084590912, 'learning_rate': 5.0100000000000005e-05, 'epoch': 6.0}\n",
            "{'loss': 0.0774, 'grad_norm': 0.33373934030532837, 'learning_rate': 4.5100000000000005e-05, 'epoch': 6.2}\n",
            "{'loss': 0.0768, 'grad_norm': 0.2730787694454193, 'learning_rate': 4.0100000000000006e-05, 'epoch': 6.4}\n",
            " 80% 1600/2000 [28:54<06:47,  1.02s/it]/usr/local/lib/python3.12/dist-packages/peft/utils/save_and_load.py:300: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0767, 'grad_norm': 0.3059028685092926, 'learning_rate': 3.51e-05, 'epoch': 6.6}\n",
            "{'loss': 0.0763, 'grad_norm': 0.2533322870731354, 'learning_rate': 3.01e-05, 'epoch': 6.8}\n",
            "{'loss': 0.0761, 'grad_norm': 0.2936413288116455, 'learning_rate': 2.51e-05, 'epoch': 7.0}\n",
            "{'loss': 0.0753, 'grad_norm': 0.24972619116306305, 'learning_rate': 2.01e-05, 'epoch': 7.2}\n",
            " 90% 1800/2000 [32:27<03:23,  1.02s/it]/usr/local/lib/python3.12/dist-packages/peft/utils/save_and_load.py:300: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "{'loss': 0.0755, 'grad_norm': 0.3006550669670105, 'learning_rate': 1.51e-05, 'epoch': 7.4}\n",
            "{'loss': 0.0755, 'grad_norm': 0.2465769350528717, 'learning_rate': 1.0100000000000002e-05, 'epoch': 7.6}\n",
            "{'loss': 0.0765, 'grad_norm': 0.28366610407829285, 'learning_rate': 5.1e-06, 'epoch': 7.8}\n",
            "{'loss': 0.0751, 'grad_norm': 0.29941362142562866, 'learning_rate': 1.0000000000000001e-07, 'epoch': 8.0}\n",
            "100% 2000/2000 [36:04<00:00,  1.02s/it]/usr/local/lib/python3.12/dist-packages/peft/utils/save_and_load.py:300: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "{'train_runtime': 2176.8912, 'train_samples_per_second': 7.35, 'train_steps_per_second': 0.919, 'train_loss': 0.1475756685733795, 'epoch': 8.0}\n",
            "100% 2000/2000 [36:16<00:00,  1.09s/it]\n",
            "Running evaluation on validation set...\n",
            "100% 200/200 [00:12<00:00, 16.62it/s]\n",
            "Evaluation metrics: {'eval_loss': 0.06926114857196808, 'eval_runtime': 12.1006, 'eval_samples_per_second': 16.528, 'eval_steps_per_second': 16.528, 'epoch': 8.0}\n",
            "/usr/local/lib/python3.12/dist-packages/peft/utils/save_and_load.py:300: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
            "  warnings.warn(\n",
            "✅ Training complete. Model and adapter saved to lora-output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json, random, torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "\n",
        "ADAPTER_DIR = \"lora-output\"\n",
        "MODEL_NAME = \"gpt2-medium\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(ADAPTER_DIR)\n",
        "base = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
        "if base.get_input_embeddings().weight.size(0) != len(tokenizer):\n",
        "    base.resize_token_embeddings(len(tokenizer))\n",
        "model = PeftModel.from_pretrained(base, ADAPTER_DIR).to(DEVICE)\n",
        "model.eval()\n",
        "\n",
        "valid = []\n",
        "with open(\"valid_v2.jsonl\",\"r\",encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        valid.append(json.loads(line))\n",
        "\n",
        "def generate(prompt):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
        "    out = model.generate(**inputs, max_new_tokens=180, do_sample=True, top_p=0.9, temperature=0.6,\n",
        "                         repetition_penalty=1.4, no_repeat_ngram_size=3, pad_token_id=tokenizer.pad_token_id)\n",
        "    return tokenizer.decode(out[0][inputs['input_ids'].shape[-1]:], skip_special_tokens=True).strip()\n",
        "\n",
        "for ex in random.sample(valid, min(10, len(valid))):\n",
        "    print(\"PROMPT:\", ex[\"prompt\"])\n",
        "    print(\"REFERENCE:\", ex[\"completion\"])\n",
        "    print(\"GENERATED:\", generate(ex[\"prompt\"]))\n",
        "    print(\"-\"*80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Ad78-WkiZj4y",
        "outputId": "c4035102-3137-400c-a1fc-11849cdaf511"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PROMPT: Instruction: Draft an email to Dr. Nair asking for a 3-day extension on the Cybersecurity assignment due to illness. Include subject line, greeting, reason, new submission date October 10, 2025, and polite closing.\n",
            "REFERENCE: Subject: Request for 3-Day Extension on Cybersecurity Assignment\n",
            "\n",
            "Dear Dr. Nair,\n",
            "\n",
            "I hope you are well. I have been unwell and was unable to complete the Cybersecurity assignment by the original deadline. I respectfully request a 3-day extension and assure you that I will submit it by October 10, 2025.\n",
            "\n",
            "Thank you for your understanding.\n",
            "\n",
            "Sincerely,\n",
            "[Your Name]\n",
            "GENERATED: Subject : Request For 2 Day Extension on Cyber Security Assignment\n",
            "I hope you are well. I have been unwell and was unableto complete the Cyber security assignments bythe original deadline . Since then , I have submitted them both online and in formal letter.Thank youfor your understanding.-Dr.Nirmala\n",
            "\n",
            "Dear Dr.[Name] 你为明商深在,\n",
            "--------------------------------------------------------------------------------\n",
            "PROMPT: Instruction: Write a polite email to Prof. Das requesting a letter of recommendation for an internship. Include subject line, greeting, purpose, deadline September 18, 2025, and polite closing.\n",
            "REFERENCE: Subject: Request for Recommendation Letter\n",
            "\n",
            "Dear Prof. Das,\n",
            "\n",
            "I hope you are doing well. I am applying for an internship and would be grateful if you could provide a recommendation letter for me. The application deadline is September 18, 2025. I would be happy to share my resume and details of the position for your reference.\n",
            "\n",
            "Thank you for considering my request.\n",
            "\n",
            "Best regards,\n",
            "[Your Name]\n",
            "GENERATED: Subject: Request For Recommendation Letter\n",
            "I hope you are doing well. I am applying for an intern position and would be grateful if someone could provide a recommendation letter for me. The application deadline is September18th, 2015. I will ensure to cover the required material promptly.*\n",
            "\n",
            " [Your Name] Dear Dr.-Dr.(Name),Thank You for considering my request for recommendation materials.The application deadline has been met; I respectfully request your recommendation letter.[*]\n",
            "\n",
            "Thankyou in advancefor Your Considerations。\n",
            "--------------------------------------------------------------------------------\n",
            "PROMPT: Instruction: Draft an email to Dr. Rao asking for a 3-day extension on the Database Systems assignment due to illness. Include subject line, greeting, reason, new submission date October 20, 2025, and polite closing.\n",
            "REFERENCE: Subject: Request for 3-Day Extension on Database Systems Assignment\n",
            "\n",
            "Dear Dr. Rao,\n",
            "\n",
            "I hope you are well. I have been unwell and was unable to complete the Database Systems assignment by the original deadline. I respectfully request a 3-day extension and assure you that I will submit it by October 20, 2025.\n",
            "\n",
            "Thank you for your understanding.\n",
            "\n",
            "Sincerely,\n",
            "[Your Name]\n",
            "GENERATED: Subject : Request For 5 Day Extension on Database System Assignment\n",
            "I hope you are well. I have been unwell and was unableto complete the Database systems assignments bythe original deadline . Since then, I have submitted them via email and assure you that I will submitthem promptly.'\n",
            "Thank you,'{Dear Dr.[Rao],}'.\n",
            "Sincerely,[Your Name]\n",
            "--------------------------------------------------------------------------------\n",
            "PROMPT: Instruction: Write a polite email to Dr. Rao asking for clarification on a Digital Logic Design assignment. Include subject line, greeting, your question, reference to deadline October 15, 2025, and polite closing.\n",
            "REFERENCE: Subject: Clarification on Digital Logic Design Assignment\n",
            "\n",
            "Dear Dr. Rao,\n",
            "\n",
            "I hope you are doing well. I am seeking clarification regarding the recent Digital Logic Design assignment due by October 15, 2025. Could you please confirm whether we are expected to include both the theoretical explanation and code implementation?\n",
            "\n",
            "Thank you for your guidance.\n",
            "\n",
            "Sincerely,\n",
            "[Your Name]\n",
            "GENERATED: Subject: Clarification of Digital Logical Design Assignment\n",
            "[Dear Dr.[Dr. Rao]\n",
            "I hope you are doing well. I am seeking clarification regarding the recent digital logic design assignment due by October 25th 2025. Could we please confirm whether our analysis includes both theoretical explanation & code implementation?\n",
            "\n",
            " [Your Name]: Thank You For Your Understanding。 ☺️\n",
            "--------------------------------------------------------------------------------\n",
            "PROMPT: Instruction: Write a polite email to Prof. Kulkarni asking for clarification on a Cloud Computing assignment. Include subject line, greeting, your question, reference to deadline November 5, 2025, and polite closing.\n",
            "REFERENCE: Subject: Clarification on Cloud Computing Assignment\n",
            "\n",
            "Dear Prof. Kulkarni,\n",
            "\n",
            "I hope you are doing well. I am seeking clarification regarding the recent Cloud Computing assignment due by November 5, 2025. Could you please confirm whether we are expected to include both the theoretical explanation and code implementation?\n",
            "\n",
            "Thank you for your guidance.\n",
            "\n",
            "Sincerely,\n",
            "[Your Name]\n",
            "GENERATED: Subject:[Dear Prof. Kapoor]\n",
            "\n",
            "\n",
            " I hope you are doing well. I am seeking clarification regarding the recent Cloud Computing Assignment due by November 10th, 2015. Could we please confirm whether it is expected that both the theoretical explanation of the code implementation & formal proof/proofing will be available online?\n",
            "--------------------------------------------------------------------------------\n",
            "PROMPT: Instruction: Write a polite email to Prof. Pillai requesting a letter of recommendation for an internship. Include subject line, greeting, purpose, deadline October 5, 2025, and polite closing.\n",
            "REFERENCE: Subject: Request for Recommendation Letter\n",
            "\n",
            "Dear Prof. Pillai,\n",
            "\n",
            "I hope you are doing well. I am applying for an internship and would be grateful if you could provide a recommendation letter for me. The application deadline is October 5, 2025. I would be happy to share my resume and details of the position for your reference.\n",
            "\n",
            "Thank you for considering my request.\n",
            "\n",
            "Best regards,\n",
            "[Your Name]\n",
            "GENERATED: Subject: Request For Recommendation Letter\n",
            "I hope you are doing well. I am applying for an intern position and would be grateful if your permission could provide me with a recommended letter code for the application process. The application deadline is October 25th , 2018 . You can find my resume at https://www!applications.google/contact/.\n",
            "Thankyou in advancefor considering my request.*\n",
            "--------------------------------------------------------------------------------\n",
            "PROMPT: Instruction: Write a formal email to Dr. Verma requesting leave of absence from class. Include subject line, greeting, reason (illness/family emergency), date October 5, 2025, and polite closing.\n",
            "REFERENCE: Subject: Request for Leave of Absence\n",
            "\n",
            "Dear Dr. Verma,\n",
            "\n",
            "I am writing to request leave from class due to personal reasons. I kindly ask for your permission to be absent until October 5, 2025. I will ensure to cover the missed material promptly.\n",
            "\n",
            "Thank you for your understanding.\n",
            "\n",
            "Regards,\n",
            "[Your Name]\n",
            "GENERATED: Subject: Request for Leave Of Absence\n",
            "\n",
            "\n",
            " [Dear Prof.Vermeer)\n",
            "I am writing to request leave from classes due TO COMPUTER/DEVICES assignment deadline September 25th . I kindly ask for your permission to be absent until then; we will ensure to cover the missed material promptly.''.\n",
            "--------------------------------------------------------------------------------\n",
            "PROMPT: Instruction: Write a polite email to Prof. Bhatia asking for clarification on a Computer Networks assignment. Include subject line, greeting, your question, reference to deadline October 25, 2025, and polite closing.\n",
            "REFERENCE: Subject: Clarification on Computer Networks Assignment\n",
            "\n",
            "Dear Prof. Bhatia,\n",
            "\n",
            "I hope you are doing well. I am seeking clarification regarding the recent Computer Networks assignment due by October 25, 2025. Could you please confirm whether we are expected to include both the theoretical explanation and code implementation?\n",
            "\n",
            "Thank you for your guidance.\n",
            "\n",
            "Sincerely,\n",
            "[Your Name]\n",
            "GENERATED: Subject : Clarification regarding Computer Systems Assignment\n",
            "[Dear Prof.Bhatti,\n",
            "--------------------------------------------------------------------------------\n",
            "PROMPT: Instruction: Draft an email to Dr. Rao asking for a 3-day extension on the Machine Learning assignment due to illness. Include subject line, greeting, reason, new submission date October 5, 2025, and polite closing.\n",
            "REFERENCE: Subject: Request for 3-Day Extension on Machine Learning Assignment\n",
            "\n",
            "Dear Dr. Rao,\n",
            "\n",
            "I hope you are well. I have been unwell and was unable to complete the Machine Learning assignment by the original deadline. I respectfully request a 3-day extension and assure you that I will submit it by October 5, 2025.\n",
            "\n",
            "Thank you for your understanding.\n",
            "\n",
            "Sincerely,\n",
            "[Your Name]\n",
            "GENERATED: Subject : Request For 4 Day Extension on Machine Language Assignment\n",
            "--------------------------------------------------------------------------------\n",
            "PROMPT: Instruction: Write a polite email to Dr. Joshi asking for clarification on a Database Systems assignment. Include subject line, greeting, your question, reference to deadline November 10, 2025, and polite closing.\n",
            "REFERENCE: Subject: Clarification on Database Systems Assignment\n",
            "\n",
            "Dear Dr. Joshi,\n",
            "\n",
            "I hope you are doing well. I am seeking clarification regarding the recent Database Systems assignment due by November 10, 2025. Could you please confirm whether we are expected to include both the theoretical explanation and code implementation?\n",
            "\n",
            "Thank you for your guidance.\n",
            "\n",
            "Sincerely,\n",
            "[Your Name]\n",
            "GENERATED: Subject:[Dear Prof. Joshiwala]\n",
            "1. Introduction\n",
            "I hope you are doing well. I am seeking clarification regarding the recent Database Systems Assignment due by October 20, 2010 . Could we please confirm whether our analysis is complete?\n",
            "Thank you for considering my request.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: build bad_words_ids to block single tokens/words\n",
        "bad_words = [\"2010\", \"2015\", \"2018\", \"你\", \"谢谢\", \"。\", \"，\"]  # add tokens/strings you want to ban\n",
        "bad_words_ids = []\n",
        "for w in bad_words:\n",
        "    toks = tokenizer.encode(w, add_special_tokens=False)\n",
        "    if len(toks) > 0:\n",
        "        bad_words_ids.append(toks)  # generate expects list of token-lists\n",
        "\n",
        "# pass bad_words_ids to generate_email_safe(..., bad_words_ids=bad_words_ids)\n"
      ],
      "metadata": {
        "id": "VmcgNqIVcIrw"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "phfA6tmjecKC",
        "outputId": "58b61cc4-34ba-4b01-d14b-c7652ef7dfab"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep 15 13:04:44 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   76C    P0             32W /   70W |    5408MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell: safe_generation_and_validation.py\n",
        "import re\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "\n",
        "# -------- config --------\n",
        "MODEL_NAME = \"gpt2-medium\"\n",
        "ADAPTER_DIR = \"lora-output\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# ------------------------\n",
        "\n",
        "# Load tokenizer + base + adapter (resizes if needed)\n",
        "tokenizer = AutoTokenizer.from_pretrained(ADAPTER_DIR)\n",
        "base = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
        "if base.get_input_embeddings().weight.size(0) != len(tokenizer):\n",
        "    base.resize_token_embeddings(len(tokenizer))\n",
        "model = PeftModel.from_pretrained(base, ADAPTER_DIR).to(DEVICE)\n",
        "model.eval()\n",
        "\n",
        "# --- safer generator ---\n",
        "def generate_email_safe(prompt,\n",
        "                        max_new_tokens=150,\n",
        "                        temperature=0.6,\n",
        "                        top_p=0.9,\n",
        "                        use_beam=False,\n",
        "                        num_beams=4,\n",
        "                        bad_words_ids=None):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
        "    gen_kwargs = dict(\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        attention_mask=inputs.get(\"attention_mask\", None),\n",
        "        max_new_tokens=int(max_new_tokens),\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        no_repeat_ngram_size=3,\n",
        "        repetition_penalty=1.4,\n",
        "    )\n",
        "    if bad_words_ids is not None:\n",
        "        gen_kwargs[\"bad_words_ids\"] = bad_words_ids\n",
        "\n",
        "    if use_beam:\n",
        "        out = model.generate(do_sample=False, num_beams=int(num_beams),\n",
        "                             early_stopping=True, **gen_kwargs)\n",
        "    else:\n",
        "        out = model.generate(do_sample=True, temperature=float(temperature),\n",
        "                             top_p=float(top_p), **gen_kwargs)\n",
        "    raw = tokenizer.decode(out[0][inputs['input_ids'].shape[-1]:], skip_special_tokens=True)\n",
        "    return raw\n",
        "\n",
        "# --- cleanup + validation + fallback ---\n",
        "CLOSINGS = [\"Sincerely\", \"Best regards\", \"Kind regards\", \"Regards\", \"With gratitude\", \"Thank you\"]\n",
        "\n",
        "def cleanup_and_validate(prompt, generated):\n",
        "    text = generated.strip()\n",
        "    # normalize whitespace and remove weird non-ascii artefacts\n",
        "    text = re.sub(r\"\\s+\\n\", \"\\n\", text)\n",
        "    text = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "\n",
        "    # Ensure Subject exists; if not, make a safe subject from prompt\n",
        "    if \"Subject\" not in text:\n",
        "        m_sub = re.search(r\"(extension|recommend|leave|clarification|thank|submit)\", prompt, flags=re.I)\n",
        "        subj = (m_sub.group(0).title() if m_sub else \"Request\")\n",
        "        text = f\"Subject: {subj}\\n\\n\" + text\n",
        "\n",
        "    # Ensure greeting uses professor name from prompt\n",
        "    prof = None\n",
        "    m = re.search(r\"(Dr\\.|Prof\\.|Professor)\\s+[A-Z][a-zA-Z]+\", prompt)\n",
        "    if m:\n",
        "        prof = m.group(0)\n",
        "        # replace any Dear ... with correct prof\n",
        "        if \"Dear\" not in text:\n",
        "            text = f\"Dear {prof},\\n\\n\" + text\n",
        "        else:\n",
        "            text = re.sub(r\"Dear\\s+[^\\n,]+\", f\"Dear {prof}\", text)\n",
        "\n",
        "    # enforce common-year 2025 heuristic: convert other years to 2025 (quick fix)\n",
        "    text = re.sub(r\"\\b(19|20)\\d{2}\\b\", lambda x: (\"2025\" if x.group(0) != \"2025\" else \"2025\"), text)\n",
        "\n",
        "    # cut after polite closing\n",
        "    for stop in CLOSINGS:\n",
        "        if stop in text:\n",
        "            text = text.split(stop)[0] + stop\n",
        "            break\n",
        "\n",
        "    # trim odd punctuation at ends\n",
        "    text = text.strip().rstrip(\".,'\\\"-\")\n",
        "\n",
        "    # Validation checks\n",
        "    valid = True\n",
        "    if prof is None:\n",
        "        valid = False\n",
        "    if \"Subject\" not in text:\n",
        "        valid = False\n",
        "    if not any(stop in text for stop in CLOSINGS):\n",
        "        valid = False\n",
        "\n",
        "    return text, valid\n",
        "\n",
        "def generate_with_fallback(prompt, use_beam=True, num_beams=4, max_new_tokens=150, temperature=0.6, top_p=0.9):\n",
        "    # Build a small bad_words_ids list to block Chinese characters and clearly wrong years\n",
        "    bad_words = []\n",
        "    # block a couple of non-ascii chars or tokens that appeared in examples\n",
        "    for s in [\"你\", \"。\", \"年\", \"2020\", \"2010\", \"2015\", \"2018\"]:\n",
        "        enc = tokenizer.encode(s, add_special_tokens=False)\n",
        "        if len(enc) > 0:\n",
        "            bad_words.append(enc)\n",
        "    bad_words_ids = bad_words if bad_words else None\n",
        "\n",
        "    raw = generate_email_safe(prompt, max_new_tokens=max_new_tokens, temperature=temperature,\n",
        "                              top_p=top_p, use_beam=use_beam, num_beams=num_beams,\n",
        "                              bad_words_ids=bad_words_ids)\n",
        "    cleaned, ok = cleanup_and_validate(prompt, raw)\n",
        "    if ok:\n",
        "        return cleaned\n",
        "    # fallback templated safe email\n",
        "    prof_m = re.search(r\"(Dr\\.|Prof\\.|Professor)\\s+[A-Z][a-zA-Z]+\", prompt)\n",
        "    prof = prof_m.group(0) if prof_m else \"[Professor]\"\n",
        "    date_m = re.search(r\"\\b(January|February|March|April|May|June|July|August|September|October|November|December)\\s+\\d{1,2},\\s*\\d{4}\\b\", prompt)\n",
        "    date = date_m.group(0) if date_m else \"[DATE]\"\n",
        "    # Decide message type quickly\n",
        "    if \"extension\" in prompt.lower():\n",
        "        subject = f\"Subject: Request for 3-Day Extension on {date}\"\n",
        "        body = f\"Dear {prof},\\n\\nI hope you are well. I have been unwell and was unable to complete the assignment by the original deadline. I respectfully request a 3-day extension and will submit by {date}.\\n\\nSincerely,\\n[Your Name]\"\n",
        "    elif \"recommend\" in prompt.lower():\n",
        "        subject = \"Subject: Request for Recommendation Letter\"\n",
        "        body = f\"Dear {prof},\\n\\nI hope you are well. I am applying for an internship with deadline {date} and would be grateful if you could provide a letter of recommendation. I can share my resume if needed.\\n\\nBest regards,\\n[Your Name]\"\n",
        "    else:\n",
        "        subject = \"Subject: Request\"\n",
        "        body = f\"Dear {prof},\\n\\n{prompt}\\n\\n{date}\\n\\nSincerely,\\n[Your Name]\"\n",
        "\n",
        "    return subject + \"\\n\\n\" + body\n"
      ],
      "metadata": {
        "id": "B4rxXbcAbjve"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the prompt (the instruction for your model)\n",
        "prompt_text = \"\"\"Instruction: Draft an email to Dr. Nair asking for a 3-day extension\n",
        "on the Cybersecurity assignment due to illness. Include subject line, greeting,\n",
        "reason, new submission date October 10, 2025, and polite closing.\"\"\"\n",
        "\n",
        "# Now call the generator\n",
        "out = generate_with_fallback(prompt_text, use_beam=True, num_beams=5, max_new_tokens=140)\n",
        "print(out)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "79G2jId-bsJY",
        "outputId": "c8c2b665-1675-44fe-edc2-c0997612e6dc"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subject: Request for 3-Day Extension on Cybersecurity Assignment\n",
            "Dear Dr. Nair,\n",
            "I hope you are well. I have been unwell and was unable to complete the Cyber Security assignment by the original deadline. I respectfully request a 3 day extension and assure you that I will submit it by October 10th, 2025.\n",
            "Thank you for your understanding.\n",
            "Sincerely\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Helper functions (paste this before evaluation/UI) ===\n",
        "import torch\n",
        "\n",
        "def generate_with_fallback(prompt, use_beam=True, num_beams=3, max_new_tokens=120, temperature=0.7):\n",
        "    \"\"\"Safe generation wrapper for your fine-tuned model.\"\"\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        try:\n",
        "            if use_beam:\n",
        "                out = model.generate(\n",
        "                    **inputs,\n",
        "                    max_new_tokens=max_new_tokens,\n",
        "                    num_beams=num_beams,\n",
        "                    early_stopping=True,\n",
        "                    no_repeat_ngram_size=3,\n",
        "                    repetition_penalty=1.2,\n",
        "                    pad_token_id=tokenizer.pad_token_id,\n",
        "                )\n",
        "            else:\n",
        "                out = model.generate(\n",
        "                    **inputs,\n",
        "                    max_new_tokens=max_new_tokens,\n",
        "                    do_sample=True,\n",
        "                    top_p=0.9,\n",
        "                    temperature=temperature,\n",
        "                    no_repeat_ngram_size=3,\n",
        "                    repetition_penalty=1.2,\n",
        "                    pad_token_id=tokenizer.pad_token_id,\n",
        "                )\n",
        "        except RuntimeError as e:\n",
        "            # fallback: shorter output\n",
        "            print(\"⚠️ Generation failed, retrying shorter:\", e)\n",
        "            out = model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=80,\n",
        "                do_sample=True,\n",
        "                top_p=0.9,\n",
        "                temperature=0.7,\n",
        "                pad_token_id=tokenizer.pad_token_id,\n",
        "            )\n",
        "\n",
        "    gen = tokenizer.decode(out[0][inputs[\"input_ids\"].shape[-1]:], skip_special_tokens=True)\n",
        "    return gen.strip()\n",
        "\n",
        "\n",
        "def cleanup_and_validate(prompt, text):\n",
        "    \"\"\"Postprocess generation: strip weird tokens, enforce polite email structure.\"\"\"\n",
        "    # cleanup\n",
        "    text = text.replace(\"\\n\\n\\n\", \"\\n\\n\").replace(\"Subject :\", \"Subject:\").strip()\n",
        "\n",
        "    # check validity\n",
        "    valid = (\n",
        "        \"Subject:\" in text\n",
        "        and \"Dear\" in text\n",
        "        and any(closing in text for closing in [\"Sincerely\", \"Regards\", \"Best\", \"Thank you\"])\n",
        "    )\n",
        "\n",
        "    return text, valid\n",
        "# ==========================================================\n"
      ],
      "metadata": {
        "id": "GQ94pKmHcM0b"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Single self-contained Gradio UI cell (paste & run in Colab)\n",
        "!pip install -q gradio\n",
        "\n",
        "import re, torch, gradio as gr\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "\n",
        "# ---------- Config ----------\n",
        "MODEL_NAME = \"gpt2-medium\"\n",
        "ADAPTER_DIR = \"lora-output\"   # where your adapter is saved\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# ----------------------------\n",
        "\n",
        "# Load tokenizer + base model + adapter (resize embeddings if needed)\n",
        "print(\"Loading tokenizer and model (this may take ~30-90s)...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(ADAPTER_DIR)\n",
        "base = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
        "\n",
        "if base.get_input_embeddings().weight.size(0) != len(tokenizer):\n",
        "    print(\"Resizing embeddings:\", base.get_input_embeddings().weight.size(0), \"->\", len(tokenizer))\n",
        "    base.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# Load LoRA adapter\n",
        "model = PeftModel.from_pretrained(base, ADAPTER_DIR).to(DEVICE)\n",
        "model.eval()\n",
        "\n",
        "# ---- Adapter sanity check ----\n",
        "if hasattr(model, \"peft_config\"):\n",
        "    print(\"✅ LoRA adapter loaded with config:\", model.peft_config)\n",
        "else:\n",
        "    print(\"⚠️ Warning: No LoRA adapter detected, running base model only!\")\n",
        "\n",
        "print(\"Model loaded on\", DEVICE)\n",
        "\n",
        "# ---------- Safe generation helpers ----------\n",
        "CLOSINGS = [\"Sincerely\", \"Best regards\", \"Kind regards\", \"Regards\", \"With gratitude\", \"Thank you\"]\n",
        "\n",
        "def generate_email_safe(prompt,\n",
        "                        max_new_tokens=150,\n",
        "                        temperature=0.6,\n",
        "                        top_p=0.9,\n",
        "                        use_beam=False,\n",
        "                        num_beams=4,\n",
        "                        bad_words_ids=None):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
        "    gen_kwargs = dict(\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        attention_mask=inputs.get(\"attention_mask\", None),\n",
        "        max_new_tokens=int(max_new_tokens),\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        no_repeat_ngram_size=3,\n",
        "        repetition_penalty=1.4,\n",
        "    )\n",
        "    if bad_words_ids is not None:\n",
        "        gen_kwargs[\"bad_words_ids\"] = bad_words_ids\n",
        "\n",
        "    try:\n",
        "        if use_beam:\n",
        "            out = model.generate(do_sample=False, num_beams=int(num_beams),\n",
        "                                 early_stopping=True, **gen_kwargs)\n",
        "        else:\n",
        "            out = model.generate(do_sample=True, temperature=float(temperature),\n",
        "                                 top_p=float(top_p), **gen_kwargs)\n",
        "    except Exception as e:\n",
        "        # fallback to safer short sampling if beam fails\n",
        "        print(\"⚠️ Generation failed, falling back:\", e)\n",
        "        out = model.generate(input_ids=inputs[\"input_ids\"], max_new_tokens=80,\n",
        "                             do_sample=True, top_p=0.9, temperature=0.7,\n",
        "                             pad_token_id=tokenizer.pad_token_id)\n",
        "    raw = tokenizer.decode(out[0][inputs[\"input_ids\"].shape[-1]:], skip_special_tokens=True)\n",
        "    return raw.strip()\n",
        "\n",
        "# (rest of cleanup_and_validate, generate_with_fallback, and Gradio UI stays same)\n",
        "\n",
        "\n",
        "# ---------- Safe generation helpers ----------\n",
        "CLOSINGS = [\"Sincerely\", \"Best regards\", \"Kind regards\", \"Regards\", \"With gratitude\", \"Thank you\"]\n",
        "\n",
        "def generate_email_safe(prompt,\n",
        "                        max_new_tokens=150,\n",
        "                        temperature=0.6,\n",
        "                        top_p=0.9,\n",
        "                        use_beam=False,\n",
        "                        num_beams=4,\n",
        "                        bad_words_ids=None):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
        "    gen_kwargs = dict(\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        attention_mask=inputs.get(\"attention_mask\", None),\n",
        "        max_new_tokens=int(max_new_tokens),\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        no_repeat_ngram_size=3,\n",
        "        repetition_penalty=1.4,\n",
        "    )\n",
        "    if bad_words_ids is not None:\n",
        "        gen_kwargs[\"bad_words_ids\"] = bad_words_ids\n",
        "\n",
        "    try:\n",
        "        if use_beam:\n",
        "            out = model.generate(do_sample=False, num_beams=int(num_beams),\n",
        "                                 early_stopping=True, **gen_kwargs)\n",
        "        else:\n",
        "            out = model.generate(do_sample=True, temperature=float(temperature),\n",
        "                                 top_p=float(top_p), **gen_kwargs)\n",
        "    except Exception as e:\n",
        "        # fallback to safer short sampling if beam fails\n",
        "        out = model.generate(input_ids=inputs[\"input_ids\"], max_new_tokens=80,\n",
        "                             do_sample=True, top_p=0.9, temperature=0.7,\n",
        "                             pad_token_id=tokenizer.pad_token_id)\n",
        "    raw = tokenizer.decode(out[0][inputs[\"input_ids\"].shape[-1]:], skip_special_tokens=True)\n",
        "    return raw.strip()\n",
        "\n",
        "def cleanup_and_validate(prompt, text):\n",
        "    # Normalize and strip weird unicode\n",
        "    text = text.strip()\n",
        "    text = re.sub(r\"\\s+\\n\", \"\\n\", text)\n",
        "    text = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "    text = text.replace(\"Subject :\", \"Subject:\")\n",
        "\n",
        "    # Ensure Subject\n",
        "    if \"Subject\" not in text:\n",
        "        m_sub = re.search(r\"(extension|recommend|leave|clarification|thank|submit)\", prompt, flags=re.I)\n",
        "        subj = (m_sub.group(0).title() if m_sub else \"Request\")\n",
        "        text = f\"Subject: {subj}\\n\\n\" + text\n",
        "\n",
        "    # Ensure greeting uses professor name from prompt\n",
        "    prof = None\n",
        "    m = re.search(r\"(Dr\\.|Prof\\.|Professor)\\s+[A-Z][a-zA-Z]+\", prompt)\n",
        "    if m:\n",
        "        prof = m.group(0)\n",
        "        if \"Dear\" not in text:\n",
        "            text = f\"Dear {prof},\\n\\n\" + text\n",
        "        else:\n",
        "            text = re.sub(r\"Dear\\s+[^\\n,]+\", f\"Dear {prof}\", text)\n",
        "\n",
        "    # Heuristic: force wrong years -> 2025\n",
        "    text = re.sub(r\"\\b(19|20)\\d{2}\\b\", lambda x: (\"2025\" if x.group(0) != \"2025\" else \"2025\"), text)\n",
        "\n",
        "    # Trim after polite closing\n",
        "    for stop in CLOSINGS:\n",
        "        if stop in text:\n",
        "            text = text.split(stop)[0] + stop\n",
        "            break\n",
        "\n",
        "    text = text.strip().rstrip(\".,'\\\"-\")\n",
        "\n",
        "    # Basic validation\n",
        "    valid = True\n",
        "    if prof is None:\n",
        "        valid = False\n",
        "    if \"Subject\" not in text:\n",
        "        valid = False\n",
        "    if not any(stop in text for stop in CLOSINGS):\n",
        "        valid = False\n",
        "\n",
        "    return text, valid\n",
        "\n",
        "def generate_with_fallback(prompt, use_beam=True, num_beams=4, max_new_tokens=150, temperature=0.6, top_p=0.9):\n",
        "    # Build a quick bad_words list to block a few problematic tokens (optional)\n",
        "    bad_words = []\n",
        "    for s in [\"你\", \"。\", \"年\", \"2010\", \"2015\", \"2018\", \"2020\"]:\n",
        "        enc = tokenizer.encode(s, add_special_tokens=False)\n",
        "        if len(enc) > 0:\n",
        "            bad_words.append(enc)\n",
        "    bad_words_ids = bad_words if bad_words else None\n",
        "\n",
        "    raw = generate_email_safe(prompt, max_new_tokens=max_new_tokens, temperature=temperature,\n",
        "                              top_p=top_p, use_beam=use_beam, num_beams=num_beams,\n",
        "                              bad_words_ids=bad_words_ids)\n",
        "    cleaned, ok = cleanup_and_validate(prompt, raw)\n",
        "    if ok:\n",
        "        return cleaned\n",
        "    # Safe templated fallback\n",
        "    prof_m = re.search(r\"(Dr\\.|Prof\\.|Professor)\\s+[A-Z][a-zA-Z]+\", prompt)\n",
        "    prof = prof_m.group(0) if prof_m else \"[Professor]\"\n",
        "    date_m = re.search(r\"\\b(January|February|March|April|May|June|July|August|September|October|November|December)\\s+\\d{1,2},\\s*\\d{4}\\b\", prompt)\n",
        "    date = date_m.group(0) if date_m else \"[DATE]\"\n",
        "    if \"extension\" in prompt.lower():\n",
        "        subject = f\"Subject: Request for 3-Day Extension on {date}\"\n",
        "        body = f\"Dear {prof},\\n\\nI hope you are well. I have been unwell and was unable to complete the assignment by the original deadline. I respectfully request a 3-day extension and will submit by {date}.\\n\\nSincerely,\\n[Your Name]\"\n",
        "    elif \"recommend\" in prompt.lower():\n",
        "        subject = \"Subject: Request for Recommendation Letter\"\n",
        "        body = f\"Dear {prof},\\n\\nI hope you are well. I am applying for an internship with deadline {date} and would be grateful if you could provide a letter of recommendation. I can share my resume if needed.\\n\\nBest regards,\\n[Your Name]\"\n",
        "    else:\n",
        "        subject = \"Subject: Request\"\n",
        "        body = f\"Dear {prof},\\n\\n{prompt}\\n\\n{date}\\n\\nSincerely,\\n[Your Name]\"\n",
        "    return subject + \"\\n\\n\" + body\n",
        "\n",
        "# ---------- Gradio UI ----------\n",
        "examples = [\n",
        "    \"Instruction: Draft an email to Dr. Nair asking for a 3-day extension on the Cybersecurity assignment due to illness. Include subject line, greeting, reason, new submission date October 10, 2025, and polite closing.\",\n",
        "    \"Instruction: Write a polite email to Prof. Das requesting a letter of recommendation for an internship. Include subject line, greeting, purpose, deadline September 18, 2025, and polite closing.\",\n",
        "    \"Instruction: Write a formal email to Dr. Verma requesting leave of absence until October 5, 2025 due to family emergency. Include subject and polite closing.\"\n",
        "]\n",
        "\n",
        "def ui_generate(prompt, temperature, max_tokens, use_beam, beams):\n",
        "    return generate_with_fallback(prompt, use_beam=use_beam, num_beams=beams,\n",
        "                                  max_new_tokens=max_tokens, temperature=temperature)\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## 📧 Email Drafter (LoRA) — production-safe\")\n",
        "    with gr.Row():\n",
        "        inp = gr.Textbox(lines=6, label=\"Instruction / Prompt\", placeholder=examples[0])\n",
        "        with gr.Column(scale=0.4):\n",
        "            temp = gr.Slider(0.2, 1.0, value=0.6, step=0.05, label=\"Temperature\")\n",
        "            max_tokens = gr.Slider(50, 400, value=200, step=10, label=\"Max new tokens\")\n",
        "            beam_switch = gr.Checkbox(label=\"Use beam search (deterministic)\", value=True)\n",
        "            beams = gr.Slider(1, 8, value=4, step=1, label=\"Num beams\")\n",
        "            gen_btn = gr.Button(\"Generate\")\n",
        "    out = gr.Textbox(label=\"Generated Email\", lines=12)\n",
        "\n",
        "    gen_btn.click(fn=ui_generate, inputs=[inp, temp, max_tokens, beam_switch, beams], outputs=out)\n",
        "\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "TjgPzQgAfT-K",
        "outputId": "3e02bc5d-67e2-4fae-cd5e-e571419be453"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading tokenizer and model (this may take ~30-90s)...\n",
            "Resizing embeddings: 50257 -> 50258\n",
            "✅ LoRA adapter loaded with config: {'default': LoraConfig(task_type='CAUSAL_LM', peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='gpt2-medium', revision=None, inference_mode=True, r=8, target_modules={'c_attn'}, exclude_modules=None, lora_alpha=32, lora_dropout=0.1, fan_in_fan_out=True, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', trainable_token_indices=None, loftq_config={}, eva_config=None, corda_config=None, use_dora=False, use_qalora=False, qalora_group_size=16, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False, target_parameters=None)}\n",
            "Model loaded on cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/layouts/column.py:59: UserWarning: 'scale' value should be an integer. Using 0.4 will cause issues.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://f487cf16efe2adf616.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f487cf16efe2adf616.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Loss curve plotting helper (paste & run in Colab) ===\n",
        "import os, json, math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "plt.rcParams.update({\"figure.figsize\": (10,5), \"font.size\": 12})\n",
        "\n",
        "# Try to auto-detect logs / trainer history\n",
        "def load_from_trainer_in_memory(varnames=(\"trainer\",\"trainer_state\")):\n",
        "    \"\"\"Attempt to find Trainer object in global namespace and extract state.log_history\"\"\"\n",
        "    import inspect, sys\n",
        "    g = globals()\n",
        "    for name in varnames:\n",
        "        if name in g:\n",
        "            obj = g[name]\n",
        "            # trainer object path: obj.state.log_history\n",
        "            try:\n",
        "                hist = obj.state.log_history\n",
        "                if isinstance(hist, list) and hist:\n",
        "                    return hist\n",
        "            except Exception:\n",
        "                pass\n",
        "    # fallback: search for any Trainer-like object in globals\n",
        "    for k,v in list(g.items()):\n",
        "        try:\n",
        "            hist = getattr(v, \"state\", None)\n",
        "            if hist:\n",
        "                log = getattr(hist, \"log_history\", None)\n",
        "                if isinstance(log, list) and log:\n",
        "                    print(f\"Found Trainer-style object in variable '{k}'.\")\n",
        "                    return log\n",
        "        except Exception:\n",
        "            pass\n",
        "    return None\n",
        "\n",
        "def load_common_logfiles():\n",
        "    candidates = [\n",
        "        \"trainer_state.json\", \"trainer.log\", \"training_log.json\", \"trainer_log.json\",\n",
        "        \"trainer_state.jsonl\", \"training_logs.jsonl\", \"trainer_state.json\"\n",
        "    ]\n",
        "    for fn in candidates:\n",
        "        if os.path.exists(fn):\n",
        "            print(\"Found log file:\", fn)\n",
        "            # try json\n",
        "            try:\n",
        "                with open(fn, \"r\", encoding=\"utf-8\") as f:\n",
        "                    content = f.read().strip()\n",
        "                    # if newline-separated json objects -> parse lines\n",
        "                    if \"\\n\" in content and content.strip().startswith(\"{\"):\n",
        "                        lines = [l for l in content.splitlines() if l.strip()]\n",
        "                        parsed = []\n",
        "                        for line in lines:\n",
        "                            try:\n",
        "                                parsed.append(json.loads(line))\n",
        "                            except:\n",
        "                                pass\n",
        "                        if parsed:\n",
        "                            return parsed\n",
        "                    # try whole file as json list\n",
        "                    parsed = json.loads(content)\n",
        "                    if isinstance(parsed, list):\n",
        "                        return parsed\n",
        "                    if isinstance(parsed, dict):\n",
        "                        # maybe dict with 'log_history'\n",
        "                        if \"log_history\" in parsed and isinstance(parsed[\"log_history\"], list):\n",
        "                            return parsed[\"log_history\"]\n",
        "                        # else try to find nested list of dicts\n",
        "                        for v in parsed.values():\n",
        "                            if isinstance(v, list) and v and isinstance(v[0], dict):\n",
        "                                return v\n",
        "            except Exception as e:\n",
        "                print(\"Could not parse\", fn, \":\", e)\n",
        "    return None\n",
        "\n",
        "# 1) Try trainer in memory\n",
        "history = load_from_trainer_in_memory()\n",
        "\n",
        "# 2) Try common files\n",
        "if history is None:\n",
        "    history = load_common_logfiles()\n",
        "\n",
        "manual_losses = {\n",
        "    # paste your train loss list here (required)\n",
        "    \"train\": [1.9644, 0.5262, 0.2245, 0.1591, 0.1274, 0.1151, 0.1041, 0.0986, 0.0962, 0.0933, 0.0903, 0.0872, 0.0852, 0.0857, 0.0837, 0.0822, 0.0817, 0.0814, 0.0813, 0.0795, 0.0782, 0.0776, 0.0773, 0.0789, 0.0779, 0.0767, 0.0763, 0.0761, 0.0753, 0.0755, 0.0765, 0.0751],\n",
        "    # optional: paste eval loss list (can be shorter). If missing, will be filled with NaN.\n",
        "    \"eval\":  [0.14017, 0.100, 0.080, 0.075, 0.072, 0.070, 0.0693],\n",
        "    # optional: explicit steps (must match final length) else auto-generated\n",
        "    # \"steps\": list(range(1, 33))\n",
        "}\n",
        "# ==========================================================\n",
        "\n",
        "# Validation\n",
        "if \"train\" not in manual_losses or not manual_losses[\"train\"]:\n",
        "    raise ValueError(\"You must provide at least manual_losses['train'] with a non-empty list.\")\n",
        "\n",
        "train = list(map(float, manual_losses[\"train\"]))\n",
        "n_train = len(train)\n",
        "\n",
        "# Build steps\n",
        "if \"steps\" in manual_losses and manual_losses[\"steps\"]:\n",
        "    steps = list(manual_losses[\"steps\"])\n",
        "    if len(steps) != n_train:\n",
        "        print(\"Warning: provided 'steps' length != train length. Ignoring provided 'steps' and regenerating.\")\n",
        "        steps = list(range(1, n_train+1))\n",
        "else:\n",
        "    steps = list(range(1, n_train+1))\n",
        "\n",
        "# Handle eval: expand/pad to match train length\n",
        "eval_vals = manual_losses.get(\"eval\", None)\n",
        "if eval_vals is None:\n",
        "    eval_arr = [math.nan] * n_train\n",
        "else:\n",
        "    eval_vals = [float(x) for x in eval_vals]\n",
        "    if len(eval_vals) == n_train:\n",
        "        eval_arr = eval_vals\n",
        "    elif len(eval_vals) < n_train:\n",
        "        # Option A: repeat last eval value to fill (less jagged)\n",
        "        # eval_arr = eval_vals + [eval_vals[-1]] * (n_train - len(eval_vals))\n",
        "        # Option B: pad with NaN (shows gaps on plot)\n",
        "        # eval_arr = eval_vals + [math.nan] * (n_train - len(eval_vals))\n",
        "        # I'll default to repeating last value — change above to Option B if you prefer NaN padding\n",
        "        eval_arr = eval_vals + [eval_vals[-1]] * (n_train - len(eval_vals))\n",
        "        print(f\"Note: 'eval' had {len(eval_vals)} points; padded to {n_train} by repeating last value.\")\n",
        "    else:\n",
        "        # If eval longer than train, truncate (rare)\n",
        "        eval_arr = eval_vals[:n_train]\n",
        "        print(f\"Note: 'eval' had {len(eval_vals)} points; truncated to {n_train} to match train length.\")\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame({\"step\": steps, \"train_loss\": train, \"eval_loss\": eval_arr})\n",
        "\n",
        "# Optional smoothing helper\n",
        "def smooth(x, window=5):\n",
        "    x = np.array(x, dtype=float)\n",
        "    if np.isnan(x).all() or len(x) < window:\n",
        "        return x\n",
        "    kernel = np.ones(window)/window\n",
        "    y = np.convolve(np.nan_to_num(x, nan=np.nanmean(x)), kernel, mode=\"same\")\n",
        "    return y\n",
        "\n",
        "train_smooth = smooth(df[\"train_loss\"].values, window=max(1, int(len(df)/20)))\n",
        "eval_smooth = smooth(df[\"eval_loss\"].values, window=max(1, int(len(df)/20)))\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(df[\"step\"], df[\"train_loss\"], label=\"Train loss\", marker=\"o\", linewidth=1.2)\n",
        "if not np.all(np.isnan(df[\"eval_loss\"].values)):\n",
        "    ax.plot(df[\"step\"], df[\"eval_loss\"], label=\"Eval loss\", marker=\"o\", linewidth=1.2)\n",
        "# smoothed\n",
        "ax.plot(df[\"step\"], train_smooth, label=\"Train (smoothed)\", linestyle=\"--\", alpha=0.9)\n",
        "if not np.all(np.isnan(eval_smooth)):\n",
        "    ax.plot(df[\"step\"], eval_smooth, label=\"Eval (smoothed)\", linestyle=\"--\", alpha=0.9)\n",
        "\n",
        "ax.set_xlabel(\"Step / Epoch\")\n",
        "ax.set_ylabel(\"Loss\")\n",
        "ax.set_title(\"Training & Validation Loss Curve\")\n",
        "ax.grid(alpha=0.2)\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "\n",
        "out_png = \"loss_curves.png\"\n",
        "plt.savefig(out_png, dpi=200)\n",
        "print(\"Saved loss plot to\", out_png)\n",
        "plt.show()\n",
        "\n",
        "# Print summary\n",
        "print(\"Summary:\")\n",
        "print(\"  Train points:\", n_train)\n",
        "print(\"  Final train loss:\", df['train_loss'].iloc[-1])\n",
        "if not np.all(np.isnan(df['eval_loss'].values)):\n",
        "    print(\"  Final eval loss:\", df['eval_loss'].iloc[-1])\n",
        "    try:\n",
        "        print(\"  Eval perplexity:\", math.exp(float(df['eval_loss'].iloc[-1])))\n",
        "    except:\n",
        "        pass\n",
        "else:\n",
        "    print(\"  No eval loss points available.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qH1OWRH0JyeR",
        "outputId": "eb910b91-7aa0-4254-81b9-71cd8e7b8b20"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: 'eval' had 7 points; padded to 32 by repeating last value.\n",
            "Saved loss plot to loss_curves.png\n",
            "Summary:\n",
            "  Train points: 32\n",
            "  Final train loss: 0.0751\n",
            "  Final eval loss: 0.0693\n",
            "  Eval perplexity: 1.071757688230542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"loss_curves.png\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "LeAqiA-pQERJ",
        "outputId": "5486a576-6a68-447d-dd78-499624906d12"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9fe153c7-bb7f-4d53-8df3-4ebdfc91f005\", \"loss_curves.png\", 112139)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image(filename=\"loss_curves.png\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 769
        },
        "id": "4RCef0ejQyim",
        "outputId": "3766c55d-6c02-4f8c-f4c0-b56e1d3ae8bf"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    }
  ]
}