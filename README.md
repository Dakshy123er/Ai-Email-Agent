


# üìß AI Email-Drafter Agent (GPT-2 Medium + LoRA)

**Author:** Daksh Yadav  
**University:** Indian Institute of Technology (IIT) Mandi  
**Department:** Bioengineering  
**Date:** September 15, 2025  

---

## üìå Project Summary

The **AI Email-Drafter Agent** is a lightweight prototype that fine-tunes a transformer language model to generate polite, structured academic emails (e.g., extension requests, recommendation requests, leave requests, clarification emails).  

To make training feasible on commodity GPUs, the project uses **LoRA (PEFT)** adapters on top of **GPT-2 Medium** (causal LM) so that only small adapter weights are trained and stored.

### üéØ Goals
- Generate emails with a subject, greeting, body and polite closing.  
- Maintain a small storage footprint (LoRA adapters vs full model checkpoints).  
- Provide deterministic post-processing to enforce structure and reduce failure modes.  
- Log full interaction history (prompt ‚Üí raw output ‚Üí cleaned output) for reproducibility.  

---

## üìÇ Deliverables in this Repository

```

Ai-Email-Agent/
‚îú‚îÄ‚îÄ demo/                     # screenshots + video demo
‚îú‚îÄ‚îÄ reports/
‚îÇ   ‚îú‚îÄ‚îÄ architecture.pdf      # architecture document (components, flow, model choices)
‚îÇ   ‚îú‚îÄ‚îÄ Data_Science_Report.pdf # data science report: fine-tuning setup + evaluation
‚îÇ   ‚îî‚îÄ‚îÄ interaction_logs.csv  # full eval interaction logs (prompt, raw, cleaned, flag)
‚îú‚îÄ‚îÄ Source Code - Python Notebook/  # Colab notebooks and supporting scripts
‚îú‚îÄ‚îÄ Project.ipynb - Colab.pdf # exported notebook PDF
‚îú‚îÄ‚îÄ train_example.jsonl       # sample training dataset
‚îú‚îÄ‚îÄ valid_example.jsonl       # sample validation / eval dataset
‚îú‚îÄ‚îÄ loss_curves.png           # training loss chart (example)
‚îú‚îÄ‚îÄ requirements.txt          # pip dependencies

‚îî‚îÄ‚îÄ README.txt                # this document

------------------------------------------------------------
Design Rationale
------------------------------------------------------------

- Base model: gpt2-medium (‚âà345M parameters). Chosen for good fluency while being runnable on a single 8‚Äì16 GB GPU with PEFT.
- PEFT / LoRA: training only small low-rank adapters -> low compute & storage cost.
- Tokenizer: GPT-2 BPE tokenizer + PAD token for batching.
- Post-processing: cleanup_and_validate() enforces Subject, Dear <Prof>, polite closing, and year normalization.
- UI: Gradio -> lightweight and easy demo deployment.

------------------------------------------------------------
Quick Start ‚Äî Colab
------------------------------------------------------------
1. Open the main notebook in 'Source Code - Python Notebook/' or 'Project.ipynb' in Google Colab.
2. Switch runtime to GPU: Runtime -> Change runtime type -> GPU.
3. Install dependencies:
   !pip install -r requirements.txt
4. Run the notebook cells in order:
   - Data preparation
   - Fine-tuning (Trainer + LoRA)
   - Evaluation + log generation
   - Demo UI (Gradio)

------------------------------------------------------------
Quick Start ‚Äî Local
------------------------------------------------------------
1. Clone repo:
   git clone https://github.com/<your-username>/Ai-Email-Agent.git
   cd Ai-Email-Agent

2. Setup environment:
   python -m venv venv
   source venv/bin/activate    # macOS/Linux
   venv\Scripts\activate       # Windows

3. Install dependencies:
   pip install -r requirements.txt

4. Run notebook or scripts for training/evaluation.

------------------------------------------------------------
Training
------------------------------------------------------------
Example training command:
python src/train_lora.py --train_file data/train.jsonl --validation_file data/valid.jsonl --output_dir lora-output --model_name_or_path gpt2-medium --per_device_train_batch_size 1 --gradient_accumulation_steps 8 --num_train_epochs 8 --learning_rate 2e-4 --fp16

Or simply run the notebook cells.

------------------------------------------------------------
Evaluation & Interaction Logs
------------------------------------------------------------
1. Prepare eval.jsonl like:
   {"prompt": "Instruction: ...", "completion": "Subject: ..."}
2. Run evaluation script/notebook to produce reports/interaction_logs.csv.
3. File contains: prompt, reference_completion, raw_generation, cleaned_generation, valid_flag, settings.

------------------------------------------------------------
Demo UI (Gradio)
------------------------------------------------------------
Run:
python src/ui_gradio.py --adapter_dir lora-output --model_name gpt2-medium

Or use the Gradio cell in the Colab notebook.

------------------------------------------------------------
Results
------------------------------------------------------------
- Training loss: 0.0751
- Validation loss: 0.0693
- Validation perplexity: ~1.072
- Pass rate (structural correctness): ~85‚Äì90%

------------------------------------------------------------
Reports
------------------------------------------------------------
- architecture.pdf -> AI agent architecture, components, flow, model choices.
- Data_Science_Report.pdf -> dataset, preprocessing, fine-tuning setup, results, evaluation.
- interaction_logs.csv -> full evaluation logs.
=======
‚îî‚îÄ‚îÄ README.md                 # this document
```

---

## üõ†Ô∏è Design Rationale

- **Base model:** `gpt2-medium` (~345M parameters). Provides a balance of fluency and trainability on a single 8‚Äì16 GB GPU.  
- **PEFT / LoRA:** trains small adapters, making the process efficient and storage-friendly.  
- **Tokenizer:** GPT-2 BPE tokenizer with a `[PAD]` token for batching.  
- **Post-processing:** `cleanup_and_validate()` ensures presence of subject, greeting, closing, and normalizes years.  
- **UI:** Gradio-based demo for simple interaction and deployment.  

---

## üöÄ Quick Start ‚Äî Google Colab

1. Open the main notebook in `Source Code - Python Notebook/` or `Project.ipynb` in **Google Colab**.  
2. Switch runtime to **GPU** (*Runtime ‚Üí Change runtime type ‚Üí GPU*).  
3. Install dependencies:  
   ```bash
   !pip install -r requirements.txt
   ```  
4. Run notebook cells in order:  
   - Data preparation  
   - Fine-tuning (Trainer + LoRA)  
   - Evaluation + log generation  
   - Demo UI (Gradio)  

---

## üíª Quick Start ‚Äî Local Setup

1. Clone this repo:
   ```bash
   git clone https://github.com/<your-username>/Ai-Email-Agent.git
   cd Ai-Email-Agent
   ```

2. Setup environment:
   ```bash
   python -m venv venv
   source venv/bin/activate    # macOS/Linux
   venv\Scripts\activate     # Windows
   ```

3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

4. Run notebooks or scripts for training/evaluation.

---

## üìä Training

Example command for fine-tuning:
```bash
python src/train_lora.py   --train_file data/train.jsonl   --validation_file data/valid.jsonl   --output_dir lora-output   --model_name_or_path gpt2-medium   --per_device_train_batch_size 1   --gradient_accumulation_steps 8   --num_train_epochs 8   --learning_rate 2e-4   --fp16
```

Or run training directly in Colab.  

---

## ‚úÖ Evaluation & Interaction Logs

1. Prepare `eval.jsonl` in the format:  
   ```json
   {"prompt": "Instruction: ...", "completion": "Subject: ..."}
   ```

2. Run evaluation to generate:  
   ```
   reports/interaction_logs.csv
   ```  

This file contains:  
`prompt, reference_completion, raw_generation, cleaned_generation, valid_flag, settings`

---

## üé® Demo UI (Gradio)

Run the Gradio app:
```bash
python src/ui_gradio.py --adapter_dir lora-output --model_name gpt2-medium
```

Or run the Gradio cell in Colab.  

---

## üìà Results

- Training loss: **0.0751**  
- Validation loss: **0.0693**  
- Validation perplexity: **~1.072**  
- Structural correctness pass rate: **85‚Äì90%**  

---

## üìë Reports

- `architecture.pdf` ‚Üí AI agent architecture (components, flow, model choices).  
- `Data_Science_Report.pdf` ‚Üí dataset, preprocessing, fine-tuning setup, results, evaluation.  
- `interaction_logs.csv` ‚Üí full evaluation logs.  

---

>>>>>>> 0515fe7 (Add detailed README.md)
